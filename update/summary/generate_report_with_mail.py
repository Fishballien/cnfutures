# -*- coding: utf-8 -*-
"""
Created on Mon Apr 28 20:15:18 2025

@author: Xintang Zheng

星星: ★ ☆ ✪ ✩ 🌟 ⭐ ✨ 🌠 💫 ⭐️
勾勾叉叉: ✓ ✔ ✕ ✖ ✅ ❎
报警啦: ⚠ ⓘ ℹ ☣
箭头: ➔ ➜ ➙ ➤ ➥ ↩ ↪
emoji: 🔔 ⏳ ⏰ 🔒 🔓 🛑 🚫 ❗ ❓ ❌ ⭕ 🚀 🔥 💧 💡 🎵 🎶 🧭 📅 🤔 🧮 🔢 📊 📈 📉 🧠 📝

"""
# -*- coding: utf-8 -*-
"""
Created on Mon Apr 28 2025

@author: Generated by Claude

Integrated Model Analysis Report Generator
This script directly generates PDF reports with model performance visualizations
without the intermediate step of saving individual plots.
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.gridspec import GridSpec
import pickle
from datetime import datetime, timedelta
import os
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
from email.mime.text import MIMEText
import argparse
import yaml
import random
import string
import traceback

# %% add sys path
file_path = Path(__file__).resolve()
file_dir = file_path.parents[0]
project_dir = file_path.parents[2]
sys.path.append(str(project_dir))

# %%
# Import required modules from project
from utils.dirutils import load_path_config
from utils.dateutils import get_previous_n_trading_day
from utils.logutils import FishStyleLogger


# %%
# Utility function for creating PDF pages with plots
def create_pdf_page(pdf, title, subtitle=None, figsize=(11, 15)):
    """Create a new page in the PDF with the given title."""
    fig = plt.figure(figsize=figsize)
    fig.suptitle(title, fontsize=16, y=0.98)
    if subtitle:
        fig.text(0.5, 0.95, subtitle, ha='center', fontsize=14)
    return fig

def add_section_title(fig, text, y, fontsize=14):
    """Add a section title to the figure."""
    fig.text(0.05, y, text, fontsize=fontsize, weight='bold')

def finalize_page(fig, pdf):
    """Add the figure to the PDF and close it."""
    pdf.savefig(fig)
    plt.close(fig)

# Function to directly plot daily returns
def plot_daily_returns_to_axis(ax, model_mapping, model_dir, start_date, end_date, fee=0.00024):
    """
    Plot daily returns as bar charts directly to the provided axis.
    """
    daily_returns = {}
    
    for tag_name, model_info in model_mapping.items():
        model_name = model_info['model_name']
        test_name = model_info['test_name']

        lob_gp_path = model_dir / model_name / 'test' / test_name / 'data' / f'gpd_predict_{model_name}.pkl'
        lob_hsr_path = model_dir / model_name / 'test' / test_name / 'data' / f'hsr_predict_{model_name}.pkl'

        with open(lob_gp_path, 'rb') as f:
            lob_gp = pickle.load(f)
        with open(lob_hsr_path, 'rb') as f:
            lob_hsr = pickle.load(f)

        lob_net = lob_gp['all']['return'] - lob_hsr['all']['avg'] * fee

        daily_returns[tag_name] = lob_net
    
    df_returns = pd.DataFrame(daily_returns)
    df_filtered = df_returns.loc[start_date:end_date]
    
    n_models = len(model_mapping)
    dates = df_filtered.index
    n_dates = len(dates)
    
    bar_width = 0.8 / n_models

    for i, tag_name in enumerate(df_filtered.columns):
        x_positions = np.arange(n_dates) + i * bar_width - (n_models - 1) * bar_width / 2
        model_color = model_mapping[tag_name]['color']
        returns = df_filtered[tag_name]

        bars = ax.bar(x_positions, returns, width=bar_width, label=tag_name, color=model_color, alpha=0.7)

        # Add value annotations on each bar
        for bar in bars:
            height = bar.get_height()
            if np.isnan(height):
                continue
            ax.annotate(f'{height*100:.2f}%',
                        xy=(bar.get_x() + bar.get_width() / 2, height),
                        xytext=(0, 5 if height >= 0 else -10),
                        textcoords="offset points",
                        ha='center', va='bottom' if height >= 0 else 'top',
                        fontsize=8)
    
    ax.set_xticks(np.arange(n_dates))
    ax.set_xticklabels([d.strftime('%Y-%m-%d') for d in dates], rotation=45, ha='right')
    
    ax.set_xlabel('Date')
    ax.set_ylabel('Daily Return')
    ax.set_title(f'Daily Returns Comparison ({start_date} to {end_date})')
    ax.legend()
    ax.grid(True, alpha=0.3)

# Function to directly plot cumulative returns
def plot_cumulative_returns_to_axis(ax, model_mapping, model_dir, start_date, fee=0.00024):
    """
    Plot cumulative returns directly to the provided axis.
    """
    daily_returns = {}
    model_colors = {}
    
    for tag_name, model_info in model_mapping.items():
        model_name = model_info['model_name']
        test_name = model_info['test_name']
        prod_name = model_info['prod_name']
        
        lob_gp_path = model_dir / model_name / 'test' / test_name / 'data' / f'gpd_predict_{model_name}.pkl'
        lob_hsr_path = model_dir / model_name / 'test' / test_name / 'data' / f'hsr_predict_{model_name}.pkl'
        
        with open(lob_gp_path, 'rb') as f:
            lob_gp = pickle.load(f)
        with open(lob_hsr_path, 'rb') as f:
            lob_hsr = pickle.load(f)
        
        # Calculate net return
        lob_net = lob_gp['all']['return'] - lob_hsr['all']['avg'] * fee
        
        # Create label with tag name and prod name
        label = f"{tag_name} ({prod_name})"
        
        # Store returns with combined label
        daily_returns[label] = lob_net
        
        # Store color mapping
        model_colors[label] = model_info['color']
    
    # Convert to DataFrame
    df_returns = pd.DataFrame(daily_returns)
    
    # Filter by start date
    df_filtered = df_returns.loc[start_date:]
    
    # Calculate cumulative returns (1 + r1) * (1 + r2) * ... - 1
    df_cumulative = (1 + df_filtered).cumprod() - 1
    
    # Plot line for each model with custom colors
    for label in df_cumulative.columns:
        ax.plot(df_cumulative.index, df_cumulative[label], label=label, 
                 color=model_colors[label], linewidth=2)
    
    # Add labels and legend
    ax.set_xlabel('Date')
    ax.set_ylabel('Cumulative Return')
    ax.set_title(f'Cumulative Returns Since {start_date}')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Format x-axis dates
    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')

# Function to directly plot price and positions
def plot_price_and_positions_to_axis(fig, axes, price_path, model_mapping, model_dir_mapping, 
                                    start_date, end_date, instruments=['IC', 'IM']):
    """
    Plot price and positions directly to the provided axes.
    """
    # Convert dates to Timestamp objects if needed
    # start_date = pd.Timestamp(start_date)
    # end_date = pd.Timestamp(end_date) + time
    
    # Load price data
    price_data = pd.read_parquet(price_path)
    
    # Load all model positions to dictionary
    model_positions = {}
    model_colors = {}
    
    for tag_name, model_config in model_mapping.items():
        model_name = model_config.get('model_name')
        test_name = model_config.get('test_name')
        model_color = model_config.get('color')
        
        model_colors[tag_name] = model_color
        
        model_pos_path = model_dir_mapping['model'] / model_name / 'test' / test_name / 'data' / f'pos_predict_{model_name}.parquet'
        
        model_pos = pd.read_parquet(model_pos_path)
        model_positions[tag_name] = model_pos
    
    # Filter for required instruments
    price_data = price_data[instruments]
    
# =============================================================================
#     # Filter data to required date range
#     price_data = price_data.loc[(price_data.index >= start_date) & (price_data.index <= end_date)]
#     
#     # Filter model positions to same date range
#     for model_name in model_positions:
#         model_positions[model_name] = model_positions[model_name].loc[
#             (model_positions[model_name].index >= start_date) & 
#             (model_positions[model_name].index <= end_date)
#         ]
# =============================================================================
        
    # Filter data to required date range
    price_data = price_data.loc[start_date:end_date]
    
    # Filter model positions to same date range
    for model_name in model_positions:
        model_positions[model_name] = model_positions[model_name].loc[start_date:end_date]
    
    # Make sure we have one axis per instrument
    if len(instruments) == 1:
        axes = [axes]
    
    for i, instrument in enumerate(instruments):
        ax1 = axes[i]
        
        # Plot price data
        price_series = price_data[instrument].dropna()
        if not price_series.empty:
            x = np.arange(len(price_series))
            x_labels = price_series.index.strftime('%Y-%m-%d %H:%M')
            
            ax1.plot(x, price_series.values, color='black', linewidth=1.5, label=f'{instrument} Price')
            ax1.set_ylabel(f'{instrument} Price', color='black', fontsize=10)
            ax1.tick_params(axis='y', labelcolor='black')
            ax1.grid(True, linestyle='--', alpha=0.7)
            
            # Create secondary y-axis for positions
            ax2 = ax1.twinx()
            
            # Plot positions for each model
            for model_name, model_pos in model_positions.items():
                pos_period = model_pos.loc[:, instrument].dropna()
                
                if not pos_period.empty:
                    aligned_pos = pos_period.reindex(price_series.index, method='ffill')
                    valid_indices = ~aligned_pos.isna()
                    if valid_indices.any():
                        valid_x = x[valid_indices.values]
                        valid_pos = aligned_pos[valid_indices].values
                        
                        color = model_colors[model_name]
                        ax2.plot(valid_x, valid_pos, color=color, 
                               linewidth=1.5, linestyle='-', 
                               label=f'{model_name}')
            
            # Set secondary axis labels
            ax2.set_ylabel('Position', fontsize=10)
            ax2.set_ylim(-1.2, 1.2)
            ax2.tick_params(axis='y')
            
            # Add horizontal line at position 0
            ax2.axhline(y=0, color='black', linestyle='--', alpha=0.7)
            
            # Add vertical lines at 9:30 AM
            nine_thirty_indices = [idx for idx, t in enumerate(price_series.index) if t.strftime('%H:%M') == '09:30']
            for idx in nine_thirty_indices:
                ax1.axvline(x=idx, color='gray', linestyle='--', linewidth=1, alpha=0.7)
                
            # Set subplot title
            ax1.set_title(f"{instrument} Price and Positions", fontsize=12)
            
            # Add legends
            ax1.legend(loc='upper left')
            handles, labels = ax2.get_legend_handles_labels()
            ax2.legend(handles, labels, loc='upper right')
            
            # Set x-axis ticks and labels for each subplot
            if len(x) > 0:
                tick_positions = np.linspace(0, len(x)-1, num=10, dtype=int)
                ax1.set_xticks(tick_positions)
                ax1.set_xticklabels([x_labels[i] for i in tick_positions], rotation=45)


# Function to directly plot comparison data
def plot_comparison_to_axis(axes, bt_df, rt_df, rt_name, model_name, tag_name, color, rt_color, is_pred=True):
    """
    Plot comparison between backtest and runtime data directly to the provided axes.
    
    Parameters:
    axes: List of axes to plot on
    bt_df: Backtest dataframe
    rt_df: Runtime dataframe
    rt_name: Runtime name
    model_name: Model name
    tag_name: Tag name for title
    color: Color for backtest line
    rt_color: Color for runtime line
    is_pred: Boolean, True if plotting predictions, False if plotting positions
    """
    common_cols = bt_df.columns.intersection(rt_df.columns)
    
    if len(common_cols) == 0:
        axes[0].text(0.5, 0.5, f"No common columns found for {model_name}", 
                     ha='center', va='center', fontsize=12, color='red')
        return
    
    for i, col in enumerate(common_cols):
        if i >= len(axes):
            break
            
        ax1 = axes[i]
        
        # Plot both predictions with specified color
        ax1.plot(bt_df.index, bt_df[col], label=f'Backtest ({model_name})', linestyle='-', marker='.', color=color)
        ax1.plot(rt_df.index, rt_df[col], label=f'Realtime ({rt_name})', linestyle='--', marker='.', color=rt_color, alpha=0.6)
        
        # Add difference plot on secondary axis
        ax2 = ax1.twinx()
        diff = bt_df[col] - rt_df[col]
        ax2.plot(bt_df.index, diff, label='Difference', color='red', alpha=0.5)
        ax2.set_ylabel('Difference', color='red')
        
        data_type = "Prediction" if is_pred else "Position"
        ax1.set_title(f'{data_type} Comparison of {col}')
        ax1.set_xlabel('Time')
        ax1.set_ylabel(f'{col} Value')
        
        # Combine legends
        lines1, labels1 = ax1.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        ax1.legend(lines1 + lines2, labels1 + labels2, loc='best')
        
        ax1.grid(True)
        plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')

# Function to load comparison data
def load_comparison_data(rt_perdist_dir, model_dir, model_info, date):
    """
    Load comparison data for a specific model and date.
    
    Returns:
    bt_pred: Backtest predictions dataframe
    rt_pred: Runtime predictions dataframe
    bt_pos: Backtest positions dataframe
    rt_pos: Runtime positions dataframe
    """
    model_name = model_info['model_name']
    test_name = model_info['test_name']
    prod_name = model_info['prod_name']
    
    # Load runtime data
    date_format = datetime.strftime(datetime.strptime(date, '%Y-%m-%d'), '%Y%m%d')
    rt_pred_path = rt_perdist_dir / f'{prod_name}/records/{date_format}.h5'
    
    # Try to load runtime data
    try:
        store = pd.HDFStore(rt_pred_path, 'r')
        rt_pred = store['predict']
        rt_pos = store['pos']
        store.close()
    except (FileNotFoundError, KeyError) as e:
        print(f"Error loading runtime data for {prod_name}: {e}")
        return None, None, None, None
    
    # Load backtest data
    try:
        bt_pred_path = model_dir / f'{model_name}/predict/predict_{model_name}.parquet'
        bt_pred_his = pd.read_parquet(bt_pred_path)
        bt_pred = bt_pred_his.loc[date]
        
        bt_pos_path = model_dir / model_name / 'test' / test_name / 'data' / f'pos_predict_{model_name}.parquet'
        bt_pos_his = pd.read_parquet(bt_pos_path)
        bt_pos = bt_pos_his.loc[date]
        
        return bt_pred, rt_pred, bt_pos, rt_pos
    except (FileNotFoundError, KeyError) as e:
        print(f"Error loading backtest data for {model_name}: {e}")
        return None, None, None, None

# Main function to generate integrated PDF report
def generate_integrated_pdf_report(
    target_date,
    period_start_date,
    period_end_date,
    plot_start_date,
    model_mapping,
    price_path,
    model_dir,
    rt_perdist_dir,
    save_dir,
    instruments=['IC', 'IM']
):
    """
    Generate integrated PDF report with all visualizations directly included.
    
    Parameters:
    target_date: Target date for comparison analysis
    period_start_date, period_end_date: Date range for daily returns and position plots
    plot_start_date: Start date for cumulative returns
    model_mapping: Dictionary with model configurations
    price_path: Path to price data file
    model_dir: Path to model directory
    rt_perdist_dir: Path to runtime persistence directory
    save_dir: Directory to save the PDF
    instruments: List of instruments to include
    """
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # Define model_dir_mapping
    model_dir_mapping = {
        'model': model_dir,
        'merged_model': model_dir
    }
    
    # Create PDF file
    pdf_path = save_dir / f"integrated_analysis_report_{target_date}.pdf"
    with PdfPages(pdf_path) as pdf:
        # Add PDF metadata
        pdf.infodict()['Title'] = f'Integrated Model Analysis Report {target_date}'
        pdf.infodict()['Author'] = 'Automated System'
        pdf.infodict()['Subject'] = 'Model Analysis Report'
        pdf.infodict()['Keywords'] = 'Model Analysis, Trading Strategies'
        pdf.infodict()['CreationDate'] = datetime.now()
        
        # ------- Page 1: Daily Returns and Cumulative Returns -------
        fig = create_pdf_page(pdf, f'Model Analysis Report', f'Date: {target_date}')
        
        # Add section titles with more space
        add_section_title(fig, '1. Recent Daily Returns', 0.92)
        add_section_title(fig, '2. Cumulative Returns', 0.48)
        
        # Create grid for plots with more space between them
        gs = GridSpec(2, 1, height_ratios=[1, 1], hspace=0.4)
        
        # More space around plots (top, bottom, left, right margins)
        gs.update(top=0.88, bottom=0.12, left=0.15, right=0.85)
        
        # Daily returns plot (smaller size)
        ax1 = fig.add_subplot(gs[0])
        try:
            plot_daily_returns_to_axis(ax1, model_mapping, model_dir, period_start_date, period_end_date)
            # Make plot smaller
            ax1.set_title("Daily Returns", fontsize=10, pad=10)
            ax1.tick_params(labelsize=8)
        except Exception as e:
            ax1.text(0.5, 0.5, f"Error generating daily returns plot: {str(e)}", 
                    ha='center', va='center', fontsize=10, color='red')
            ax1.set_title("Daily Returns (Error)", fontsize=10)
        
        # Cumulative returns plot (smaller size)
        ax2 = fig.add_subplot(gs[1])
        try:
            plot_cumulative_returns_to_axis(ax2, model_mapping, model_dir, plot_start_date)
            # Make plot smaller
            ax2.set_title("Cumulative Returns", fontsize=10, pad=10)
            ax2.tick_params(labelsize=8)
        except Exception as e:
            ax2.text(0.5, 0.5, f"Error generating cumulative returns plot: {str(e)}", 
                    ha='center', va='center', fontsize=10, color='red')
            ax2.set_title("Cumulative Returns (Error)", fontsize=10)
        
        finalize_page(fig, pdf)
        
        # ------- Page 2: Price and Positions -------
        fig = create_pdf_page(pdf, f'Model Analysis Report - Price and Positions', f'Date: {target_date}')
        
        # Add section title with more space
        add_section_title(fig, '3. Price and Position Data', 0.92)
        
        # Create grid for price and position plots with more space between plots
        gs = GridSpec(len(instruments), 1, height_ratios=[1] * len(instruments), hspace=0.4)
        
        # More space around plots
        gs.update(top=0.88, bottom=0.12, left=0.15, right=0.85)
        
        axes = [fig.add_subplot(gs[i]) for i in range(len(instruments))]
        
        try:
            plot_price_and_positions_to_axis(
                fig, axes, price_path, model_mapping, model_dir_mapping, 
                period_start_date, period_end_date, instruments
            )
            
            # Make plots smaller
            for ax in axes:
                ax.tick_params(labelsize=8)
                # if hasattr(ax, 'title') and ax.title is not None:
                #     ax.title.set_fontsize(10)
                    # ax.title.set_pad(10)
                
                # Reduce legend size if it exists
                # if ax.get_legend() is not None:
                #     ax.get_legend().set_fontsize(7)
        except Exception as e:
            traceback.print_exc()
            axes[0].text(0.5, 0.5, f"Error generating price and positions plot: {str(e)}", 
                    ha='center', va='center', fontsize=10, color='red')
            axes[0].set_title("Price and Positions (Error)", fontsize=10)
        
        finalize_page(fig, pdf)
        
        # ------- Pages for Model Comparisons -------
        for tag_name, model_info in model_mapping.items():
            # Load comparison data
            bt_pred, rt_pred, bt_pos, rt_pos = load_comparison_data(
                rt_perdist_dir, model_dir, model_info, target_date
            )
            
            if bt_pred is None or rt_pred is None or bt_pos is None or rt_pos is None:
                continue
                
            prod_name = model_info['prod_name']
            model_name = model_info['model_name']
            color = model_info['color']
            rt_color = model_info['rt_color']
            
            # ------- Predictions Comparison Page -------
            common_pred_cols = bt_pred.columns.intersection(rt_pred.columns)
            if len(common_pred_cols) > 0:
                fig = create_pdf_page(
                    pdf, 
                    f'Model Analysis Report - Predictions Comparison', 
                    f'{tag_name}: {prod_name} vs {model_name} on {target_date}'
                )
                
                # Add section title with more space
                add_section_title(fig, f'4. Prediction Comparison for {tag_name}', 0.92)
                
                # Calculate number of plots needed
                n_cols = len(common_pred_cols)
                
                # If there are many columns, consider showing fewer per page
                max_plots_per_page = 3  # Adjust based on preference
                if n_cols > max_plots_per_page:
                    # Handle only max_plots_per_page at a time
                    # In a production scenario, you might want to create multiple pages
                    n_cols = max_plots_per_page
                    common_pred_cols = list(common_pred_cols)[:max_plots_per_page]
                
                # Create grid with more space between plots
                gs = GridSpec(n_cols, 1, height_ratios=[1] * n_cols, hspace=0.4)
                
                # More space around plots
                gs.update(top=0.88, bottom=0.12, left=0.15, right=0.85)
                
                axes = [fig.add_subplot(gs[i]) for i in range(n_cols)]
                
                try:
                    plot_comparison_to_axis(
                        axes, bt_pred, rt_pred, prod_name, model_name, 
                        tag_name, color, rt_color, is_pred=True
                    )
                    
                    # Make plots smaller
                    for ax in axes:
                        ax.tick_params(labelsize=8)
                        if hasattr(ax, 'title') and ax.title is not None:
                            ax.title.set_fontsize(10)
                            ax.title.set_pad(10)
                        
                        # Reduce legend size if it exists
                        if ax.get_legend() is not None:
                            ax.get_legend().set_fontsize(7)
                except Exception as e:
                    axes[0].text(0.5, 0.5, f"Error generating predictions comparison: {str(e)}", 
                            ha='center', va='center', fontsize=10, color='red')
                
                finalize_page(fig, pdf)
            
            # ------- Positions Comparison Page -------
            common_pos_cols = bt_pos.columns.intersection(rt_pos.columns)
            if len(common_pos_cols) > 0:
                fig = create_pdf_page(
                    pdf, 
                    f'Model Analysis Report - Positions Comparison', 
                    f'{tag_name}: {prod_name} vs {model_name} on {target_date}'
                )
                
                # Add section title with more space
                add_section_title(fig, f'5. Position Comparison for {tag_name}', 0.92)
                
                # Calculate number of plots needed
                n_cols = len(common_pos_cols)
                
                # If there are many columns, consider showing fewer per page
                max_plots_per_page = 3  # Adjust based on preference
                if n_cols > max_plots_per_page:
                    # Handle only max_plots_per_page at a time
                    n_cols = max_plots_per_page
                    common_pos_cols = list(common_pos_cols)[:max_plots_per_page]
                
                # Create grid with more space between plots
                gs = GridSpec(n_cols, 1, height_ratios=[1] * n_cols, hspace=0.4)
                
                # More space around plots
                gs.update(top=0.88, bottom=0.12, left=0.15, right=0.85)
                
                axes = [fig.add_subplot(gs[i]) for i in range(n_cols)]
                
                try:
                    plot_comparison_to_axis(
                        axes, bt_pos, rt_pos, prod_name, model_name, 
                        tag_name, color, rt_color, is_pred=False
                    )
                    
                    # Make plots smaller
                    for ax in axes:
                        ax.tick_params(labelsize=8)
                        if hasattr(ax, 'title') and ax.title is not None:
                            ax.title.set_fontsize(10)
                            ax.title.set_pad(10)
                        
                        # Reduce legend size if it exists
                        if ax.get_legend() is not None:
                            ax.get_legend().set_fontsize(7)
                except Exception as e:
                    axes[0].text(0.5, 0.5, f"Error generating positions comparison: {str(e)}", 
                            ha='center', va='center', fontsize=10, color='red')
                
                finalize_page(fig, pdf)
    
    print(f"Integrated PDF report generated at: {pdf_path}")
    return pdf_path

# Function to send email with PDF attachment
def send_email_with_pdf(pdf_path, email_config, target_date, log=None):
    if log is None:
        log = FishStyleLogger()
    
    try:
        # Create message container
        msg = MIMEMultipart()
        msg['From'] = email_config['sender_email']
        msg['To'] = ', '.join(email_config['recipient_emails'])
        msg['Subject'] = f"{email_config['subject_template'].format(date=target_date)}_{generate_random_string(5)}"
        
        # Attach message body
        body = email_config['body_template'].format(date=target_date)
        msg.attach(MIMEText(body, 'plain'))
        
        # Attach PDF file
        with open(pdf_path, 'rb') as file:
            part = MIMEApplication(file.read(), Name=os.path.basename(pdf_path))
        part['Content-Disposition'] = f'attachment; filename="{os.path.basename(pdf_path)}"'
        msg.attach(part)
        
        # 重点改动：用 SMTP_SSL
        with smtplib.SMTP_SSL(email_config['smtp_server'], email_config['smtp_port']) as server:
            server.login(email_config['sender_email'], email_config['sender_password'])
            server.sendmail(
                email_config['sender_email'],
                email_config['recipient_emails'],
                msg.as_string()
            )
        
        log.success(f"Email with PDF report successfully sent to {', '.join(email_config['recipient_emails'])}")
        return True
    
    except Exception as e:
        log.error(f"Failed to send email: {str(e)}")
        return False


def generate_random_string(length=10):
    """
    生成一串随机字符（字母+数字）。
    
    参数:
        length (int): 要生成的字符长度，默认是10。
        
    返回:
        str: 随机生成的字符串。
    """
    characters = string.ascii_letters + string.digits
    random_string = ''.join(random.choices(characters, k=length))
    return random_string


def generate_report(
    config_name,
    target_date=None,
    delay=1,
    lookback=30,
    plot_start=None,
    send_email=False
):
    """
    Generate a daily model performance report with specified parameters.
    
    Args:
        config_name (str): Configuration name (without extension)
        target_date (str, optional): Target date in format YYYY-MM-DD. 
                                    If not specified, uses today minus delay days.
        delay (int, optional): Number of days to go back from today (if target_date not specified).
                              Defaults to 1.
        lookback (int, optional): Number of days to look back from target_date to determine period_start.
                                 Defaults to 30.
        plot_start (str, optional): Plot start date for cumulative returns in format YYYY-MM-DD.
                                   If not specified, uses period_start.
        send_email (bool, optional): Whether to send the generated report via email.
                                    Defaults to False.
    
    Returns:
        int: 0 if successful, 1 if failed
    """
    # Initialize logger
    log = FishStyleLogger()
    
    # Calculate actual target_date (if not specified)
    actual_target_date = target_date
    if actual_target_date is None:
        actual_target_date = datetime.strptime(
            get_previous_n_trading_day(datetime.today().strftime('%Y%m%d'), delay),
            '%Y%m%d'
        ).strftime('%Y-%m-%d')
    
    # Calculate period_start (lookback days from target_date)
    target_date_obj = datetime.strptime(actual_target_date, '%Y-%m-%d')
    period_start_date = target_date_obj - timedelta(days=lookback)
    period_start = period_start_date.strftime('%Y-%m-%d')
    
    # Use the same period_start for plot_start if not specified
    plot_start = plot_start if plot_start else period_start
    
    log.info(f"Report period: {period_start} to {actual_target_date} (lookback: {lookback} days)")
    log.info(f"Plot start date for cumulative returns: {plot_start}")
    
    # Load path configuration
    path_config = load_path_config(project_dir)
    
    # Load configuration file
    workflow_param_dir = Path(path_config['param'])
    config_path = workflow_param_dir / 'daily_report' / f'{config_name}.yaml'
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # Extract required parameters from config
    model_mapping = config.get('model_mapping', {})
    price_path = Path(config.get('price_path', '.'))
    model_dir = Path(config.get('model_dir', '.'))
    rt_perdist_dir = Path(config.get('rt_perdist_dir', '.'))
    save_dir = Path(config.get('save_dir', '.')) / actual_target_date
    instruments = config.get('instruments', ['IC', 'IM'])
    
    log.info(f"Generating integrated PDF report for {actual_target_date}")
    
    # Generate report
    pdf_path = generate_integrated_pdf_report(
        target_date=actual_target_date,
        period_start_date=period_start,
        period_end_date=actual_target_date,
        plot_start_date=plot_start,
        model_mapping=model_mapping,
        price_path=price_path,
        model_dir=model_dir,
        rt_perdist_dir=rt_perdist_dir,
        save_dir=save_dir,
        instruments=instruments
    )
    
    if pdf_path is None:
        log.error("Failed to generate PDF report")
        return 1
    
    log.success(f"PDF report generated successfully: {pdf_path}")
    
    # Send email if requested
    if send_email and 'email' in config:
        email_result = send_email_with_pdf(
            pdf_path=pdf_path,
            email_config=config['email'],
            target_date=actual_target_date,
            log=log
        )
        
        if not email_result:
            log.warning("Email sending failed, but PDF was generated successfully")
    elif send_email:
        log.warning("Email configuration not found in config file")
    
    return 0


def main():
    """
    Main function to run the report generation process.
    
    Parses command line arguments and calls the generate_report function
    with the parsed parameters.
    """
    parser = argparse.ArgumentParser(description='Generate and email a daily model performance report')
    parser.add_argument('-c', '--config', type=str, required=True, 
                        help='Configuration name (without extension)')
    parser.add_argument('-t', '--target_date', type=str, default=None, 
                        help='Target date in format YYYY-MM-DD. If not specified, uses today minus delay days.')
    parser.add_argument('-d', '--delay', type=int, default=1, 
                        help='Number of days to go back from today (if target_date not specified)')
    parser.add_argument('-lb', '--lookback', type=int, default=30, 
                        help='Number of days to look back from target_date to determine period_start')
    parser.add_argument('-ps', '--plot_start', type=str, default=None,
                        help='Plot start date for cumulative returns in format YYYY-MM-DD')
    parser.add_argument('-e', '--email', action='store_true', 
                        help='Send the generated report via email')
    
    args = parser.parse_args()
    
    # Call the new function with parsed arguments
    return generate_report(
        config_name=args.config,
        target_date=args.target_date,
        delay=args.delay,
        lookback=args.lookback,
        plot_start=args.plot_start,
        send_email=args.email
    )


# %%
if __name__ == "__main__":
    
    sys.exit(main())
