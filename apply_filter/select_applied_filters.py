# -*- coding: utf-8 -*-
"""
Created on Wed May 29 2025

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
import os
import sys
import json
import yaml
from pathlib import Path
import pandas as pd
import numpy as np
from functools import partial
from datetime import datetime
from typing import Union, Dict, Any, Optional, List
from concurrent.futures import ThreadPoolExecutor, as_completed
import time


# %% add sys path
file_path = Path(__file__).resolve()
file_dir = file_path.parents[0]
project_dir = file_path.parents[1]
sys.path.append(str(project_dir))


# %%
from utils.dirutils import load_path_config
from utils.timeutils import period_shortcut
from utils.fsutils import find_files_with_prefix, copy_file
from utils.datautils import deduplicate_nested_list
from synthesis.factor_cluster import cluster_factors


def extend_metrics(eval_res):
    """
    Extend evaluation metrics with additional calculated values.
    
    Parameters:
    -----------
    eval_res : DataFrame
        DataFrame containing the base evaluation results with metrics like
        'net_return_annualized', 'hsr', and correlation metrics.
        
    Returns:
    -----------
    eval_res : DataFrame
        The same DataFrame with additional calculated metrics.
    """
    # Calculate net_ppt for different directions
    for direction_suffix in ('', '_long_only', '_short_only'):
        eval_res[f'net_ppt{direction_suffix}'] = (eval_res[f'net_return_annualized{direction_suffix}'] 
                                                  / eval_res[f'hsr{direction_suffix}'] / 245)
    
    # Calculate average correlations for different time windows
    for corr_type in ('cont', 'dist'):
        lt720_cols = [f'corr_{corr_type}_wd30', f'corr_{corr_type}_wd60', 
                      f'corr_{corr_type}_wd240', f'corr_{corr_type}_wd720']
        eval_res[f'corr_{corr_type}_lt720_avg'] = eval_res[lt720_cols].mean(axis=1)
    
    return eval_res


def filter_func_dynamic_for_applied_filters(eval_res, conditions, min_count=1, 
                                           sort_target=None, sort_ascending=False,
                                           target_tag_name=None, target_process_name=None, 
                                           target_factor_name=None, target_test_name=None,
                                           reference_process_name=None, reference_factor_name=None,
                                           reference_test_name=None, reference_tag_name=None):
    """
    é’ˆå¯¹applied filtersçš„åŠ¨æ€ç­›é€‰å‡½æ•°ï¼Œä¿æŒä¸åŸå§‹filter_func_dynamicçš„å…¼å®¹æ€§
    
    å‚æ•°:
        eval_res (pd.DataFrame): è¯„ä¼°ç»“æœæ•°æ®æ¡†
        conditions (list): ç­›é€‰æ¡ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡ä»¶æ˜¯åŒ…å«metric, threshold, directionç­‰çš„å­—å…¸
        min_count (int): æœ€å°‘ä¿ç•™çš„å› å­æ•°é‡
        sort_target (str): æ’åºç›®æ ‡æŒ‡æ ‡
        sort_ascending (bool): æ˜¯å¦å‡åºæ’åº
        target_tag_name (str): ç›®æ ‡tag_nameï¼Œæ›¿ä»£åŸæ¥çš„pred_nameåŠŸèƒ½
        target_process_name (str): ç›®æ ‡process_name
        target_factor_name (str): ç›®æ ‡factor_name  
        target_test_name (str): ç›®æ ‡test_name
        reference_process_name (str): å‚è€ƒprocess_nameï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨è®¾ç½®
        reference_factor_name (str): å‚è€ƒfactor_nameï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ¨æ–­
        reference_test_name (str): å‚è€ƒtest_nameï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„
        reference_tag_name (str): å‚è€ƒtag_nameï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨è®¾ç½®ä¸ºorg_alpha
        
    è¿”å›:
        pd.Series: å¸ƒå°”ç´¢å¼•ï¼Œè¡¨ç¤ºæ˜¯å¦é€šè¿‡ç­›é€‰
    """
    # å¦‚æœæŒ‡å®šäº†ç›®æ ‡æ¡ä»¶ï¼Œå…ˆè¿›è¡Œé¢„ç­›é€‰
    if any([target_tag_name, target_process_name, target_factor_name, target_test_name]):
        target_mask = pd.Series([True] * len(eval_res), index=eval_res.index)
        
        if target_tag_name is not None:
            target_mask &= (eval_res['tag_name'] == target_tag_name)
        if target_process_name is not None:
            target_mask &= (eval_res['process_name'] == target_process_name)
        if target_factor_name is not None:
            target_mask &= (eval_res['factor_name'] == target_factor_name)
        if target_test_name is not None:
            target_mask &= (eval_res['test_name'] == target_test_name)
            
        eval_res_filtered = eval_res[target_mask]
    else:
        eval_res_filtered = eval_res.copy()
        target_mask = pd.Series([True] * len(eval_res), index=eval_res.index)
    
    if len(eval_res_filtered) == 0:
        print("è­¦å‘Š: ç›®æ ‡ç­›é€‰åæ²¡æœ‰æ•°æ®")
        return pd.Series([False] * len(eval_res), index=eval_res.index)
    
    # åº”ç”¨ç­›é€‰æ¡ä»¶
    selected_mask = pd.Series([True] * len(eval_res_filtered), index=eval_res_filtered.index)
    
    for condition in conditions:
        metric = condition['metric']
        threshold = condition.get('threshold')
        direction = condition.get('direction', 'ge')
        use_reference = condition.get('use_reference', False)
        
        if use_reference:
            # è‡ªåŠ¨è®¾ç½®å‚è€ƒåŸºå‡†
            ref_tag_name = reference_tag_name or 'org_alpha'
            ref_process_name = reference_process_name or ''
            ref_test_name = reference_test_name or eval_res['test_name'].iloc[0]
            
            if reference_factor_name is None:
                # ä»org_alphaä¸­æ¨æ–­factor_name
                org_alpha_rows = eval_res[
                    (eval_res['tag_name'] == ref_tag_name) & 
                    (eval_res['process_name'] == ref_process_name) &
                    (eval_res['test_name'] == ref_test_name)
                ]
                if len(org_alpha_rows) > 0:
                    ref_factor_name = org_alpha_rows['factor_name'].iloc[0]
                else:
                    raise ValueError(f"æ— æ³•æ‰¾åˆ°å‚è€ƒåŸºå‡†: tag_name={ref_tag_name}, "
                                   f"process_name={ref_process_name}, test_name={ref_test_name}")
            else:
                ref_factor_name = reference_factor_name
            
            # æ‰¾åˆ°å‚è€ƒè¡Œ
            ref_condition = (
                (eval_res['process_name'] == ref_process_name) & 
                (eval_res['factor_name'] == ref_factor_name) &
                (eval_res['test_name'] == ref_test_name) &
                (eval_res['tag_name'] == ref_tag_name)
            )
            
            ref_rows = eval_res[ref_condition]
            if len(ref_rows) == 0:
                raise ValueError(f"æ— æ³•æ‰¾åˆ°å‚è€ƒåŸºå‡†è¡Œ: process_name={ref_process_name}, "
                               f"factor_name={ref_factor_name}, test_name={ref_test_name}, "
                               f"tag_name={ref_tag_name}")
            
            ref_value = ref_rows[metric].iloc[0]
            print(f"ä½¿ç”¨å‚è€ƒåŸºå‡†å€¼: {metric} = {ref_value}")
            
            # ç›¸å¯¹äºå‚è€ƒåŸºå‡†è¿›è¡Œç­›é€‰
            if direction == 'ge':
                condition_mask = eval_res_filtered[metric] >= ref_value
            elif direction == 'gt':
                condition_mask = eval_res_filtered[metric] > ref_value
            elif direction == 'le':
                condition_mask = eval_res_filtered[metric] <= ref_value
            elif direction == 'lt':
                condition_mask = eval_res_filtered[metric] < ref_value
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ç­›é€‰æ–¹å‘: {direction}")
        else:
            # ç»å¯¹é˜ˆå€¼ç­›é€‰
            if threshold is None:
                raise ValueError(f"ä½¿ç”¨ç»å¯¹é˜ˆå€¼ç­›é€‰æ—¶ï¼Œthresholdä¸èƒ½ä¸ºNone")
                
            if direction == 'ge':
                condition_mask = eval_res_filtered[metric] >= threshold
            elif direction == 'gt':
                condition_mask = eval_res_filtered[metric] > threshold
            elif direction == 'le':
                condition_mask = eval_res_filtered[metric] <= threshold
            elif direction == 'lt':
                condition_mask = eval_res_filtered[metric] < threshold
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ç­›é€‰æ–¹å‘: {direction}")
        
        selected_mask &= condition_mask
        print(f"åº”ç”¨æ¡ä»¶ {metric} {direction} {threshold if not use_reference else 'reference'}: "
              f"å‰©ä½™ {selected_mask.sum()} ä¸ªå› å­")
    
    # æ£€æŸ¥æœ€å°æ•°é‡è¦æ±‚
    if selected_mask.sum() < min_count and sort_target is not None:
        print(f"ç­›é€‰ç»“æœå°‘äºæœ€å°æ•°é‡ {min_count}ï¼Œä½¿ç”¨æ’åºæ–¹å¼ä¿ç•™å‰ {min_count} ä¸ª")
        sorted_indices = eval_res_filtered[sort_target].sort_values(ascending=sort_ascending).index[:min_count]
        selected_mask = eval_res_filtered.index.isin(sorted_indices)
    
    # å°†ç»“æœæ˜ å°„å›åŸå§‹æ•°æ®æ¡†
    result_mask = pd.Series([False] * len(eval_res), index=eval_res.index)
    result_mask.loc[eval_res_filtered.index] = selected_mask
    result_mask &= target_mask  # ç¡®ä¿åªè¿”å›ç›®æ ‡èŒƒå›´å†…çš„ç»“æœ
    
    return result_mask


class AppliedFiltersSelector:
    """
    åº”ç”¨è¿‡æ»¤å™¨ç»“æœé€‰æ‹©å™¨ç±»ï¼šç”¨äºç­›é€‰ã€èšç±»å¹¶ä¿å­˜æœ€ä½³è¿‡æ»¤åçš„å› å­
    """
    
    def __init__(self, select_name: str, merge_name: str, test_eval_filtered_alpha_name: str):
        """
        åˆå§‹åŒ–åº”ç”¨è¿‡æ»¤å™¨ç»“æœé€‰æ‹©å™¨
        
        å‚æ•°:
            select_name (str): é€‰æ‹©é…ç½®åç§°
            merge_name (str): åˆå¹¶åç§°
            test_eval_filtered_alpha_name (str): æµ‹è¯•è¯„ä¼°è¿‡æ»¤alphaåç§°
        """
        self.select_name = select_name
        self.merge_name = merge_name
        self.test_eval_filtered_alpha_name = test_eval_filtered_alpha_name
        
        # åŠ è½½é¡¹ç›®è·¯å¾„é…ç½®
        self.project_dir = project_dir
        self.path_config = load_path_config(self.project_dir)
        self.result_dir = Path(self.path_config['result'])
        self.param_dir = Path(self.path_config['param']) / 'select_applied_filters'
        
        # è®¾ç½®ç›¸å…³ç›®å½•
        self.test_eval_dir = self.result_dir / 'test_eval_filtered_alpha' / f'{merge_name}_{test_eval_filtered_alpha_name}'
        self.select_dir = self.result_dir / 'select_applied_filters' / f'{merge_name}_{test_eval_filtered_alpha_name}_{select_name}'
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        config_path = self.param_dir / f'{select_name}.yaml'
        self.config = self._load_config(config_path)
        
        # è®¾ç½®ç­›é€‰å‚æ•°
        self.cluster_params = self.config['cluster']
        self.cluster_params.update({'test_dir': None})  # applied filtersä¸éœ€è¦test_dir
        
        # åˆ›å»ºç­›é€‰å‡½æ•°ï¼Œæ”¯æŒåŸå§‹filter_func_dynamicçš„å‚æ•°ç»“æ„
        filter_config = self.config['filter']
        self.filter_func = partial(
            filter_func_dynamic_for_applied_filters,
            conditions=filter_config['conditions'],
            min_count=filter_config.get('min_count', 1),
            sort_target=filter_config.get('sort_target'),
            sort_ascending=filter_config.get('sort_ascending', False),
            target_tag_name=filter_config.get('target_tag_name'),
            target_process_name=filter_config.get('target_process_name'),
            target_factor_name=filter_config.get('target_factor_name'),
            target_test_name=filter_config.get('target_test_name'),
            reference_process_name=filter_config.get('reference_process_name'),
            reference_factor_name=filter_config.get('reference_factor_name'),
            reference_test_name=filter_config.get('reference_test_name'),
            reference_tag_name=filter_config.get('reference_tag_name')
        )

    def _load_config(self, config_path: Union[str, Path]) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        å‚æ•°:
            config_path (str or Path): é…ç½®æ–‡ä»¶è·¯å¾„
            
        è¿”å›:
            Dict[str, Any]: é…ç½®å­—å…¸
        """
        config_path = Path(config_path)
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        return config
    
    def run_one_period(self, date_start: str, date_end: str):
        """
        å¯¹æŒ‡å®šæœŸé—´è¿è¡Œç­›é€‰
        
        Args:
            date_start: å¼€å§‹æ—¥æœŸ
            date_end: ç»“æŸæ—¥æœŸ
        """
        # ç”ŸæˆæœŸé—´åç§°
        period_name = period_shortcut(date_start, date_end)
        
        # è®¾ç½®ç»“æœç›®å½•
        res_dir = self.select_dir / period_name
        res_selected_dir = res_dir / 'selected'
        res_selected_info_dir = res_selected_dir / 'factor_info'
        res_selected_plot_dir = res_selected_dir / 'plot'
        
        # åˆ›å»ºç›®å½•
        res_selected_info_dir.mkdir(parents=True, exist_ok=True)
        res_selected_plot_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"å¼€å§‹å¯¹æœŸé—´ {period_name} è¿›è¡Œåº”ç”¨è¿‡æ»¤å™¨ç»“æœç­›é€‰")
        
        # è¯»å–è¯„ä¼°ç»“æœ
        # ç›´æ¥åœ¨test_eval_dirä¸‹å¯»æ‰¾å¯¹åº”æœŸé—´çš„å­ç›®å½•
        period_test_eval_dir = self.test_eval_dir / period_name / 'eval'
        
        if not period_test_eval_dir.exists():
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æœŸé—´ {period_name} çš„è¯„ä¼°ç›®å½•: {period_test_eval_dir}")
            return
            
        # å¯»æ‰¾è¯„ä¼°æ–‡ä»¶
        eval_files = list(period_test_eval_dir.glob('eval_res_*.csv'))
        if not eval_files:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æœŸé—´ {period_name} çš„è¯„ä¼°ç»“æœæ–‡ä»¶")
            return
            
        eval_file = eval_files[0]  # å–ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡ä»¶
            
        print(f"è¯»å–è¯„ä¼°ç»“æœæ–‡ä»¶: {eval_file}")
        eval_res = pd.read_csv(eval_file)
        
        # æ‰©å±•è¯„ä¼°æŒ‡æ ‡
        eval_res = extend_metrics(eval_res)
        
        print(f"è¯„ä¼°ç»“æœåŒ…å« {len(eval_res)} ä¸ªå› å­")
        
        # åº”ç”¨ç­›é€‰å‡½æ•°
        print(f"å¼€å§‹ç­›é€‰ï¼Œåˆå§‹å› å­æ•°é‡: {len(eval_res)}")
        
        selected_mask = self.filter_func(eval_res)
        selected_eval_res = eval_res[selected_mask].copy()
        
        print(f"ç­›é€‰åå‰©ä½™ {len(selected_eval_res)} ä¸ªå› å­")
        
        # å¦‚æœç­›é€‰åæ²¡æœ‰å› å­ï¼Œåˆ™è·³è¿‡åç»­æ­¥éª¤
        if selected_eval_res.empty:
            print(f"æœŸé—´ {period_name} ç­›é€‰åæ²¡æœ‰å› å­")
            return
        
        # èšç±»
        if len(selected_eval_res) < 2:
            selected_eval_res['group'] = 1
            print("å› å­æ•°é‡å°‘äº2ä¸ªï¼Œä¸è¿›è¡Œèšç±»")
        else:
            print(f"å¯¹ {len(selected_eval_res)} ä¸ªå› å­è¿›è¡Œèšç±»")
            
            # ä¸ºèšç±»å‡†å¤‡å‚æ•°ï¼Œå»æ‰test_dir
            cluster_params_copy = self.cluster_params.copy()
            cluster_params_copy.pop('test_dir', None)
            
            try:
                groups = cluster_factors(
                    selected_eval_res, 
                    datetime.strptime(date_start, '%Y%m%d'), 
                    datetime.strptime(date_end, '%Y%m%d'), 
                    **cluster_params_copy
                )
                selected_eval_res['group'] = groups
                print(f"èšç±»å®Œæˆï¼Œå…± {selected_eval_res['group'].nunique()} ä¸ªç»„")
            except Exception as e:
                print(f"èšç±»å¤±è´¥: {str(e)}ï¼Œè®¾ç½®æ‰€æœ‰å› å­ä¸ºåŒä¸€ç»„")
                selected_eval_res['group'] = 1
        
        # ä¿å­˜ç­›é€‰ç»“æœ
        self._save_results(selected_eval_res, res_dir, res_selected_dir)
        
        print(f"æœŸé—´ {period_name} åº”ç”¨è¿‡æ»¤å™¨ç»“æœç­›é€‰å®Œæˆ")
      
    def _save_results(self, final_factors: pd.DataFrame, res_dir: Path, res_selected_dir: Path) -> None:
        """
        ä¿å­˜ç­›é€‰ç»“æœå’Œå¤åˆ¶ç›¸å…³æ–‡ä»¶
        
        å‚æ•°:
            final_factors (pd.DataFrame): ç­›é€‰åçš„å› å­æ•°æ®
            res_dir (Path): ç»“æœç›®å½•
            res_selected_dir (Path): é€‰å®šç»“æœç›®å½•
        """
        print(f"ä¿å­˜ {len(final_factors)} ä¸ªç­›é€‰åçš„å› å­")
        
        # ä¸ºapplied filtersåˆ›å»ºå› å­åˆ—è¡¨æ ¼å¼
        # è¿™é‡Œä½¿ç”¨tag_nameå’Œfactor_nameæ¥æ ‡è¯†å› å­
        final_factors_to_list = []
        for idx in final_factors.index:
            tag_name = final_factors.loc[idx, 'tag_name']
            factor_name = final_factors.loc[idx, 'factor_name']
            test_name = final_factors.loc[idx, 'test_name']
            final_factors_to_list.append([tag_name, factor_name, test_name])
        
        final_factors_to_list = deduplicate_nested_list(final_factors_to_list)
        
        # ä¿å­˜åˆ°ç»“æœç›®å½•
        with open(res_dir / 'final_factors.json', 'w', encoding='utf-8') as f:
            json.dump(final_factors_to_list, f, ensure_ascii=False, indent=4)
            
        print(f"å› å­åˆ—è¡¨å·²ä¿å­˜åˆ°: {res_dir / 'final_factors.json'}")
        
        # ä¿å­˜ç­›é€‰åçš„å› å­ä¿¡æ¯åˆ°CSVæ–‡ä»¶
        final_factors.to_csv(res_dir / 'final_selected_factors.csv', index=False)
        print(f"ç­›é€‰ç»“æœå·²ä¿å­˜åˆ°: {res_dir / 'final_selected_factors.csv'}")
        
        # å¯é€‰ï¼šå¤åˆ¶ç›¸å…³æ–‡ä»¶ï¼ˆå¦‚æœé…ç½®ä¸­å¯ç”¨ï¼‰
        if self.config.get('copy_selected', False):
            print("æ³¨æ„: åº”ç”¨è¿‡æ»¤å™¨ç»“æœé€šå¸¸ä¸å¤åˆ¶æ–‡ä»¶ï¼Œå› ä¸ºæµ‹è¯•æ–‡ä»¶ç»“æ„ä¸åŒ")
            # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å®ç°æ–‡ä»¶å¤åˆ¶é€»è¾‘
            # ä½†ç”±äºapplied filtersçš„æ–‡ä»¶ç»“æ„ä¸åŸå§‹factorsä¸åŒï¼Œå¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†
        
        print(f"å·²å®Œæˆåº”ç”¨è¿‡æ»¤å™¨ç»“æœç­›é€‰ï¼Œç»“æœä¿å­˜è‡³: {res_dir}")


def example_usage():
    """
    ä½¿ç”¨ç¤ºä¾‹
    """
    # åˆå§‹åŒ–AppliedFiltersSelector
    afs = AppliedFiltersSelector(
        select_name='basic_select',
        merge_name='merge_v1',
        test_eval_filtered_alpha_name='basic_test_eval'
    )
    
    # å¯¹å•ä¸ªæœŸé—´è¿›è¡Œç­›é€‰
    afs.run_one_period('20240101', '20240331')
    
    print("åº”ç”¨è¿‡æ»¤å™¨ç»“æœç­›é€‰å®Œæˆ")


if __name__ == "__main__":
    example_usage()