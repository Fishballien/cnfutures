# -*- coding: utf-8 -*-
"""
Created on Wed May 29 2025

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
import os
import sys
import json
import yaml
from pathlib import Path
import pandas as pd
import numpy as np
from functools import partial
from datetime import datetime
from typing import Union, Dict, Any, Optional, List
from concurrent.futures import ThreadPoolExecutor, as_completed
import time


# %% add sys path
file_path = Path(__file__).resolve()
file_dir = file_path.parents[0]
project_dir = file_path.parents[1]
sys.path.append(str(project_dir))


# %%
from utils.dirutils import load_path_config
from utils.timeutils import period_shortcut
from utils.fsutils import find_files_with_prefix, copy_file
from utils.datautils import deduplicate_nested_list
from synthesis.factor_cluster import cluster_factors
from synthesis.filter_methods import filter_func_dynamic


def extend_metrics(eval_res):
    """
    Extend evaluation metrics with additional calculated values.
    
    Parameters:
    -----------
    eval_res : DataFrame
        DataFrame containing the base evaluation results with metrics like
        'net_return_annualized', 'hsr', and correlation metrics.
        
    Returns:
    -----------
    eval_res : DataFrame
        The same DataFrame with additional calculated metrics.
    """
    # Calculate net_ppt for different directions
    for direction_suffix in ('', '_long_only', '_short_only'):
        eval_res[f'net_ppt{direction_suffix}'] = (eval_res[f'net_return_annualized{direction_suffix}'] 
                                                  / eval_res[f'hsr{direction_suffix}'] / 245)
    
    # Calculate average correlations for different time windows
    for corr_type in ('cont', 'dist'):
        lt720_cols = [f'corr_{corr_type}_wd30', f'corr_{corr_type}_wd60', 
                      f'corr_{corr_type}_wd240', f'corr_{corr_type}_wd720']
        eval_res[f'corr_{corr_type}_lt720_avg'] = eval_res[lt720_cols].mean(axis=1)
    
    return eval_res


class AppliedFiltersSelector:
    """
    åº”ç”¨è¿‡æ»¤å™¨ç»“æœé€‰æ‹©å™¨ç±»ï¼šç”¨äºç­›é€‰ã€èšç±»å¹¶ä¿å­˜æœ€ä½³è¿‡æ»¤åçš„å› å­
    """
    
    def __init__(self, select_name: str, merge_name: str, test_eval_filtered_alpha_name: str):
        """
        åˆå§‹åŒ–åº”ç”¨è¿‡æ»¤å™¨ç»“æœé€‰æ‹©å™¨
        
        å‚æ•°:
            select_name (str): é€‰æ‹©é…ç½®åç§°
            merge_name (str): åˆå¹¶åç§°
            test_eval_filtered_alpha_name (str): æµ‹è¯•è¯„ä¼°è¿‡æ»¤alphaåç§°
        """
        self.select_name = select_name
        self.merge_name = merge_name
        self.test_eval_filtered_alpha_name = test_eval_filtered_alpha_name
        
        # åŠ è½½é¡¹ç›®è·¯å¾„é…ç½®
        self.project_dir = project_dir
        self.path_config = load_path_config(self.project_dir)
        self.result_dir = Path(self.path_config['result'])
        self.param_dir = Path(self.path_config['param']) / 'select_applied_filters'
        
        # è®¾ç½®ç›¸å…³ç›®å½•
        self.eval_dir = self.result_dir / 'eval_filtered_alpha' / f'{merge_name}_{test_eval_filtered_alpha_name}'
        self.select_dir = self.result_dir / 'select_applied_filters' / f'{merge_name}_{test_eval_filtered_alpha_name}_{select_name}'
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        config_path = self.param_dir / f'{select_name}.yaml'
        self.config = self._load_config(config_path)
        
        # è®¾ç½®ç­›é€‰å‚æ•°
        self.cluster_params = self.config['cluster']
        self.cluster_params.update({'test_dir': None})  # applied filtersä¸éœ€è¦test_dir
        
        # åˆ›å»ºç­›é€‰å‡½æ•°ï¼Œç›´æ¥ä½¿ç”¨é…ç½®ä¸­çš„å‚æ•°
        filter_config = self.config['filter']
        
        self.filter_func = partial(
            filter_func_dynamic,
            **filter_config
        )

    def _load_config(self, config_path: Union[str, Path]) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        å‚æ•°:
            config_path (str or Path): é…ç½®æ–‡ä»¶è·¯å¾„
            
        è¿”å›:
            Dict[str, Any]: é…ç½®å­—å…¸
        """
        config_path = Path(config_path)
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        return config
    
    def _apply_target_filter(self, eval_res):
        """
        åº”ç”¨ç›®æ ‡ç­›é€‰æ¡ä»¶ï¼ˆå¦‚æœé…ç½®ä¸­æœ‰target_filterå‚æ•°ï¼‰
        
        å‚æ•°:
            eval_res (pd.DataFrame): è¯„ä¼°ç»“æœæ•°æ®æ¡†
            
        è¿”å›:
            pd.DataFrame: ç­›é€‰åçš„æ•°æ®æ¡†
        """
        target_filter = self.config['filter'].get('target_filter')
        if target_filter is None:
            return eval_res
        
        target_mask = pd.Series([True] * len(eval_res), index=eval_res.index)
        
        for col, value in target_filter.items():
            if col in eval_res.columns:
                target_mask &= (eval_res[col] == value)
            else:
                print(f"è­¦å‘Š: ç›®æ ‡ç­›é€‰åˆ— '{col}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        filtered_data = eval_res[target_mask]
        print(f"ç›®æ ‡ç­›é€‰: {len(eval_res)} -> {len(filtered_data)} ä¸ªå› å­")
        
        return filtered_data
    
    def _get_factor_data_dir(self, factor_row):
        """
        æ ¹æ®å› å­ä¿¡æ¯è·å–æ•°æ®ç›®å½•è·¯å¾„ï¼Œå‚è€ƒcluster_factorsä¸­çš„é€»è¾‘
        
        å‚æ•°:
            factor_row: åŒ…å«å› å­ä¿¡æ¯çš„è¡Œæ•°æ®
            
        è¿”å›:
            Path: æ•°æ®ç›®å½•è·¯å¾„
        """
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨test_data_diråˆ—
        has_test_data_dir = 'test_data_dir' in factor_row.index
        
        if has_test_data_dir:
            test_data_dir = factor_row.get('test_data_dir')
            # æ£€æŸ¥test_data_diræ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
            if pd.notna(test_data_dir) and str(test_data_dir).strip():
                # ç›´æ¥ä½¿ç”¨test_data_dirä½œä¸ºæ•°æ®ç›®å½•çš„çˆ¶ç›®å½•
                return Path(test_data_dir).parent
        
        # å¦‚æœæ²¡æœ‰test_data_diræˆ–è€…ä¸ºç©ºï¼Œä½¿ç”¨ä¼ ç»Ÿçš„è·¯å¾„æ„å»ºæ–¹å¼
        # å¯¹äºapplied filtersï¼Œæˆ‘ä»¬éœ€è¦ä»evalç»“æœä¸­æ¨æ–­è·¯å¾„ç»“æ„
        test_name = factor_row.get('test_name', '')
        tag_name = factor_row.get('tag_name', '')
        process_name = factor_row.get('process_name', '')
        
        # æ„å»ºä¼ ç»Ÿè·¯å¾„ï¼štest_dir / test_name / tag_name / process_name
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ²¡æœ‰test_dirï¼Œæ‰€ä»¥éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        # å¯èƒ½éœ€è¦ä»é…ç½®æˆ–å…¶ä»–åœ°æ–¹è·å–åŸºç¡€è·¯å¾„
        base_test_dir = self.result_dir / 'test'  # å‡è®¾åŸºç¡€æµ‹è¯•ç›®å½•
        
        if isinstance(tag_name, str) and tag_name.strip():
            target_dir = base_test_dir / test_name / tag_name / process_name
        else:
            target_dir = base_test_dir / test_name / process_name
            
        return target_dir
    
    def run_one_period(self, date_start: str, date_end: str):
        """
        å¯¹æŒ‡å®šæœŸé—´è¿è¡Œç­›é€‰
        
        Args:
            date_start: å¼€å§‹æ—¥æœŸ
            date_end: ç»“æŸæ—¥æœŸ
        """
        # ç”ŸæˆæœŸé—´åç§°
        period_name = period_shortcut(date_start, date_end)
        
        # è®¾ç½®ç»“æœç›®å½•
        res_dir = self.select_dir / period_name
        res_selected_dir = res_dir / 'selected'
        res_selected_info_dir = res_selected_dir / 'factor_info'
        res_selected_plot_dir = res_selected_dir / 'plot'
        
        # åˆ›å»ºç›®å½•
        res_selected_info_dir.mkdir(parents=True, exist_ok=True)
        res_selected_plot_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"å¼€å§‹å¯¹æœŸé—´ {period_name} è¿›è¡Œåº”ç”¨è¿‡æ»¤å™¨ç»“æœç­›é€‰")
        
        # è¯»å–è¯„ä¼°ç»“æœ
        # ç›´æ¥åœ¨test_dirä¸‹å¯»æ‰¾å¯¹åº”æœŸé—´çš„å­ç›®å½•
        period_eval_dir = self.eval_dir / period_name / 'eval'
        
        if not period_eval_dir.exists():
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æœŸé—´ {period_name} çš„è¯„ä¼°ç›®å½•: {period_eval_dir}")
            return
            
        # å¯»æ‰¾è¯„ä¼°æ–‡ä»¶
        eval_files = list(period_eval_dir.glob('eval_res_*.csv'))
        if not eval_files:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æœŸé—´ {period_name} çš„è¯„ä¼°ç»“æœæ–‡ä»¶")
            return
            
        eval_file = eval_files[0]  # å–ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡ä»¶
            
        print(f"è¯»å–è¯„ä¼°ç»“æœæ–‡ä»¶: {eval_file}")
        eval_res = pd.read_csv(eval_file)
        
        # æ‰©å±•è¯„ä¼°æŒ‡æ ‡
        eval_res = extend_metrics(eval_res)
        
        print(f"è¯„ä¼°ç»“æœåŒ…å« {len(eval_res)} ä¸ªå› å­")
        
        # åº”ç”¨ç›®æ ‡ç­›é€‰
        eval_res_filtered = self._apply_target_filter(eval_res)
        
        if eval_res_filtered.empty:
            print(f"æœŸé—´ {period_name} ç›®æ ‡ç­›é€‰åæ²¡æœ‰å› å­")
            return
        
        # åº”ç”¨ç­›é€‰å‡½æ•°
        print(f"å¼€å§‹ç­›é€‰ï¼Œç­›é€‰å‰å› å­æ•°é‡: {len(eval_res_filtered)}")
        
        selected_mask = self.filter_func(eval_res_filtered)
        selected_eval_res = eval_res_filtered[selected_mask].copy()
        
        print(f"ç­›é€‰åå‰©ä½™ {len(selected_eval_res)} ä¸ªå› å­")
        
        # å¦‚æœç­›é€‰åæ²¡æœ‰å› å­ï¼Œåˆ™è·³è¿‡åç»­æ­¥éª¤
        if selected_eval_res.empty:
            print(f"æœŸé—´ {period_name} ç­›é€‰åæ²¡æœ‰å› å­")
            return
        
        # èšç±»
        if len(selected_eval_res) < 2:
            selected_eval_res['group'] = 1
            print("å› å­æ•°é‡å°‘äº2ä¸ªï¼Œä¸è¿›è¡Œèšç±»")
        else:
            print(f"å¯¹ {len(selected_eval_res)} ä¸ªå› å­è¿›è¡Œèšç±»")
            
            # ä¸ºèšç±»å‡†å¤‡å‚æ•°ï¼Œå»æ‰test_dir
            cluster_params_copy = self.cluster_params.copy()
            
            # try:
            groups = cluster_factors(
                selected_eval_res, 
                date_start, 
                date_end, 
                **cluster_params_copy
            )
            selected_eval_res['group'] = groups
            print(f"èšç±»å®Œæˆï¼Œå…± {selected_eval_res['group'].nunique()} ä¸ªç»„")
            # except Exception as e:
            #     print(f"èšç±»å¤±è´¥: {str(e)}ï¼Œè®¾ç½®æ‰€æœ‰å› å­ä¸ºåŒä¸€ç»„")
            #     selected_eval_res['group'] = 1
        
        # ä¿å­˜ç­›é€‰ç»“æœ
        self._save_results(selected_eval_res, res_dir, res_selected_dir)
        
        print(f"æœŸé—´ {period_name} åº”ç”¨è¿‡æ»¤å™¨ç»“æœç­›é€‰å®Œæˆ")
      
    def _save_results(self, final_factors: pd.DataFrame, res_dir: Path, res_selected_dir: Path) -> None:
        """
        ä¿å­˜ç­›é€‰ç»“æœå’Œå¤åˆ¶ç›¸å…³æ–‡ä»¶
        
        å‚æ•°:
            final_factors (pd.DataFrame): ç­›é€‰åçš„å› å­æ•°æ®
            res_dir (Path): ç»“æœç›®å½•
            res_selected_dir (Path): é€‰å®šç»“æœç›®å½•
        """
        print(f"ä¿å­˜ {len(final_factors)} ä¸ªç­›é€‰åçš„å› å­")
        
        # ä¸ºapplied filtersåˆ›å»ºå› å­åˆ—è¡¨æ ¼å¼
        # è¿™é‡Œä½¿ç”¨tag_nameå’Œfactor_nameæ¥æ ‡è¯†å› å­
        final_factors_to_list = []
        for idx in final_factors.index:
            tag_name = final_factors.loc[idx, 'tag_name']
            factor_name = final_factors.loc[idx, 'factor']
            test_name = final_factors.loc[idx, 'test_name']
            final_factors_to_list.append([tag_name, factor_name, test_name])
        
        final_factors_to_list = deduplicate_nested_list(final_factors_to_list)
        
        # ä¿å­˜åˆ°ç»“æœç›®å½•
        with open(res_dir / 'final_factors.json', 'w', encoding='utf-8') as f:
            json.dump(final_factors_to_list, f, ensure_ascii=False, indent=4)
            
        print(f"å› å­åˆ—è¡¨å·²ä¿å­˜åˆ°: {res_dir / 'final_factors.json'}")
        
        # ä¿å­˜ç­›é€‰åçš„å› å­ä¿¡æ¯åˆ°CSVæ–‡ä»¶
        final_factors.to_csv(res_dir / 'final_selected_factors.csv', index=False)
        print(f"ç­›é€‰ç»“æœå·²ä¿å­˜åˆ°: {res_dir / 'final_selected_factors.csv'}")
        
        # å¤åˆ¶ç›¸å…³æ–‡ä»¶ï¼ˆå¦‚æœé…ç½®ä¸­å¯ç”¨ï¼‰
        if self.config.get('copy_selected', False):
            print("å¼€å§‹å¤åˆ¶ç­›é€‰åçš„å› å­ç›¸å…³æ–‡ä»¶...")
            
            # åˆ›å»ºç»“æœç›®å½•
            res_selected_info_dir = res_selected_dir / 'factor_info'
            res_selected_plot_dir = res_selected_dir / 'plot'
            res_selected_info_dir.mkdir(parents=True, exist_ok=True)
            res_selected_plot_dir.mkdir(parents=True, exist_ok=True)
            
            # æ”¶é›†æ‰€æœ‰éœ€è¦å¤åˆ¶çš„æ–‡ä»¶å¯¹
            file_pairs = []
            
            # éå†æ‰€æœ‰éœ€è¦å¤åˆ¶çš„å› å­
            for idx in final_factors.index:
                factor_name = final_factors.loc[idx, 'factor']
                
                try:
                    # è·å–å› å­æ•°æ®ç›®å½•
                    target_dir = self._get_factor_data_dir(final_factors.loc[idx])
                    
                    # æ”¶é›†å› å­ä¿¡æ¯å›¾è¡¨æ–‡ä»¶
                    factor_info_plot_dir = target_dir / 'factor_info'
                    if factor_info_plot_dir.exists():
                        factor_info_files = find_files_with_prefix(factor_info_plot_dir, factor_name)
                        
                        for file_name in factor_info_files:
                            source_file = factor_info_plot_dir / file_name
                            target_file = res_selected_info_dir / file_name
                            if source_file.exists():
                                file_pairs.append((source_file, target_file))
                    else:
                        print(f"è­¦å‘Š: å› å­ä¿¡æ¯ç›®å½•ä¸å­˜åœ¨: {factor_info_plot_dir}")
                    
                    # æ”¶é›†å› å­å›¾è¡¨æ–‡ä»¶
                    factor_plot_source = target_dir / 'plot' / f'{factor_name}.jpg'
                    factor_plot_target = res_selected_plot_dir / f'{factor_name}.jpg'
                    
                    if factor_plot_source.exists():
                        file_pairs.append((factor_plot_source, factor_plot_target))
                    else:
                        print(f"è­¦å‘Š: å› å­å›¾è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {factor_plot_source}")
                        
                except Exception as e:
                    print(f"è­¦å‘Š: å¤„ç†å› å­ {factor_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    continue
            
            # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤åˆ¶æ‰€æœ‰æ–‡ä»¶
            if file_pairs:
                print(f"å¼€å§‹å¹¶è¡Œå¤åˆ¶ {len(file_pairs)} ä¸ªæ–‡ä»¶...")
                start_time = time.time()
                
                # ä½¿ç”¨ThreadPoolExecutorè¿›è¡Œå¹¶è¡Œå¤åˆ¶
                with ThreadPoolExecutor(max_workers=min(len(file_pairs), 8)) as executor:
                    # ä¸ºæ¯ä¸ªæ–‡ä»¶å¯¹æäº¤å¤åˆ¶ä»»åŠ¡
                    future_to_file = {
                        executor.submit(copy_file, src, dst): (src, dst) 
                        for src, dst in file_pairs
                    }
                    
                    # æ”¶é›†ç»“æœ
                    success_count = 0
                    for future in as_completed(future_to_file):
                        src, dst = future_to_file[future]
                        try:
                            result = future.result()
                            if result:
                                success_count += 1
                                print(f"æˆåŠŸå¤åˆ¶: {src.name}")
                            else:
                                print(f"å¤åˆ¶å¤±è´¥: {src.name}")
                        except Exception as e:
                            print(f"å¤åˆ¶ {src.name} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                
                end_time = time.time()
                duration = end_time - start_time
                print(f"å¤åˆ¶å®Œæˆ! æˆåŠŸ: {success_count}/{len(file_pairs)}, ç”¨æ—¶: {duration:.2f} ç§’")
            else:
                print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤åˆ¶çš„æ–‡ä»¶ã€‚")
        else:
            print("é…ç½®ä¸­æœªå¯ç”¨æ–‡ä»¶å¤åˆ¶åŠŸèƒ½ (copy_selected=False)")
        
        print(f"å·²å®Œæˆåº”ç”¨è¿‡æ»¤å™¨ç»“æœç­›é€‰ï¼Œç»“æœä¿å­˜è‡³: {res_dir}")


def example_usage():
    """
    ä½¿ç”¨ç¤ºä¾‹
    """
    # åˆå§‹åŒ–AppliedFiltersSelector
    afs = AppliedFiltersSelector(
        select_name='gt_nsr_ppt',
        merge_name='batch_till20_newma_batch_test_v3_icim_nsr22_m0',
        test_eval_filtered_alpha_name='corr_and_diffusion_v1'
    )
    
    # å¯¹å•ä¸ªæœŸé—´è¿›è¡Œç­›é€‰
    from datetime import datetime
    afs.run_one_period(datetime(2015, 1, 1), datetime(2016, 1, 1))
    
    print("åº”ç”¨è¿‡æ»¤å™¨ç»“æœç­›é€‰å®Œæˆ")


if __name__ == "__main__":
    example_usage()