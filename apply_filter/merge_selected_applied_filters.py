# -*- coding: utf-8 -*-
"""
Created on Wed May 29 2025

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
# %%
import os
import sys
import json
from pathlib import Path
import pandas as pd
import numpy as np
from tqdm import tqdm
from typing import Union, Dict, Any
import yaml
from functools import partial
import concurrent.futures


# %% add sys path
file_path = Path(__file__).resolve()
file_dir = file_path.parents[0]
project_dir = file_path.parents[1]
sys.path.append(str(project_dir))


# %%
from utils.dirutils import load_path_config
from utils.datautils import compute_dataframe_dict_average
from utils.timeutils import period_shortcut
from test_and_eval.factor_tester import FactorTesterByContinuous, FactorTesterByDiscrete
from data_processing.ts_trans import ts_normalize
from test_and_eval.factor_evaluation import eval_one_factor_one_period


# %%
def process_group_applied_filters(args):
    """
    å¤„ç†åº”ç”¨è¿‡æ»¤å™¨é€‰å®šå› å­çš„å•ä¸ªç»„çš„å‡½æ•°ï¼Œé€‚ç”¨äºå¹¶è¡Œæ‰§è¡Œ
    
    Args:
        args: åŒ…å«æ‰€éœ€å‚æ•°çš„å…ƒç»„ (group_num, group_info, group_normalization_func, 
              factor_normalization_func, price_path, fstart)
        
    Returns:
        tuple: (group_num, group_scaled) - ç»„å·å’Œç»„çš„æ ‡å‡†åŒ–åçš„å¹³å‡å› å­
    """
    (group_num, group_info, group_normalization_func, factor_normalization_func, 
     price_path, fstart) = args
    
    price_data = pd.read_parquet(price_path)
    price_index = price_data.loc[fstart:].index
    group_factor_dict, group_weight_dict = {}, {}
    
    # å¤„ç†ç»„å†…æ¯ä¸ªå› å­
    for idx in group_info.index:
        root_dir = group_info.loc[idx, 'root_dir']
        factor_name = group_info.loc[idx, 'factor']
        direction = group_info.loc[idx, 'direction']
        
        # ç›´æ¥ä»root_dirè¯»å–å› å­æ–‡ä»¶
        fac_path = Path(root_dir) / f'{factor_name}.parquet'
        
        if not fac_path.exists():
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°å› å­æ–‡ä»¶: {fac_path}")
            continue
            
        fac = pd.read_parquet(fac_path)
        
        # ä½¿ç”¨å•å› å­æ ‡å‡†åŒ–å‡½æ•°
        scaled_fac = factor_normalization_func(fac)
        
        # å­˜å‚¨å› å­åŠå…¶æƒé‡
        group_factor_dict[idx] = (direction * scaled_fac).reindex(index=price_index).replace([-np.inf, np.inf], np.nan).fillna(0)
        group_weight_dict[idx] = 1
    
    # å¦‚æœç»„å†…æ²¡æœ‰æœ‰æ•ˆå› å­ï¼Œè¿”å›é›¶å› å­
    if not group_factor_dict:
        zero_factor = pd.DataFrame(0, index=price_index, columns=price_data.columns)
        return group_num, zero_factor
    
    # è®¡ç®—ç»„å¹³å‡å€¼å¹¶ä½¿ç”¨ç»„æ ‡å‡†åŒ–å‡½æ•°æ ‡å‡†åŒ–
    group_avg = compute_dataframe_dict_average(group_factor_dict, group_weight_dict)
    group_scaled = group_normalization_func(group_avg).replace([-np.inf, np.inf], np.nan).fillna(0)
    return group_num, group_scaled


class AppliedFiltersMerger:
    
    def __init__(self, fac_merge_name, test_eval_filtered_alpha_name, select_name, filter_merge_name, max_workers=None):
        """
        åˆå§‹åŒ–AppliedFiltersMergerï¼Œç”¨äºåˆå¹¶åº”ç”¨è¿‡æ»¤å™¨é€‰å®šçš„å› å­ã€‚
        
        Args:
            fac_merge_name: å› å­åˆå¹¶é…ç½®åç§°ï¼ˆå†³å®šä»å“ªé‡Œè¯»filtered factorsï¼‰
            test_eval_filtered_alpha_name: æµ‹è¯•è¯„ä¼°è¿‡æ»¤alphaé…ç½®åç§°
            select_name: é€‰æ‹©é…ç½®åç§°  
            filter_merge_name: è¿‡æ»¤å™¨åˆå¹¶é…ç½®åç§°ï¼ˆå†³å®šåˆå¹¶æ–¹æ³•ï¼‰
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°
        """
        self.fac_merge_name = fac_merge_name
        self.test_eval_filtered_alpha_name = test_eval_filtered_alpha_name
        self.select_name = select_name
        self.filter_merge_name = filter_merge_name
        self.max_workers = max_workers
        
        # åŠ è½½è·¯å¾„é…ç½®
        self.path_config = load_path_config(project_dir)
        self.result_dir = Path(self.path_config['result'])
        self.param_dir = Path(self.path_config['param']) / 'merge_selected_applied_filters'
        
        # è®¾ç½®ç›®å½•è·¯å¾„
        self.filtered_base_dir = self.result_dir / 'apply_filters_on_merged' / f'{fac_merge_name}'
        self.select_dir = self.result_dir / 'select_applied_filters' / f'{fac_merge_name}_{test_eval_filtered_alpha_name}_{select_name}'
        self.merged_dir = self.result_dir / 'merge_selected_applied_filters' / f'{fac_merge_name}_{test_eval_filtered_alpha_name}_{select_name}_{filter_merge_name}'
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        config_path = self.param_dir / f'{filter_merge_name}.yaml'
        self.config = self._load_config(config_path)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.merged_dir.mkdir(parents=True, exist_ok=True)
        
        self._init_utils()
        
    def _load_config(self, config_path: Union[str, Path]) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        å‚æ•°:
            config_path (str or Path): é…ç½®æ–‡ä»¶è·¯å¾„
            
        è¿”å›:
            Dict[str, Any]: é…ç½®å­—å…¸
        """
        config_path = Path(config_path)
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        return config
    
    def _init_utils(self):
        # ä»é…ç½®ä¸­è¯»å–ä¸¤ä¸ªä¸åŒçš„é¢„å¤„ç†å‚æ•°
        group_preprocess_params = self.config['group_preprocess_params']
        factor_preprocess_params = self.config['factor_preprocess_params']
        
        # åˆå§‹åŒ–ä¸¤ä¸ªä¸åŒçš„æ ‡å‡†åŒ–å‡½æ•°
        self.group_normalization_func = partial(ts_normalize, param=group_preprocess_params)
        self.factor_normalization_func = partial(ts_normalize, param=factor_preprocess_params)
        
    def run_one_period(self, date_start, date_end):
        # ç”ŸæˆæœŸé—´åç§°
        period_name = period_shortcut(date_start, date_end)
        
        # è®¾ç½®æ­¤æœŸé—´çš„ç›®å½•
        self.select_period_dir = self.select_dir / period_name
        self.merged_period_dir = self.merged_dir / period_name
        self.merged_period_dir.mkdir(parents=True, exist_ok=True)
        
        self._merge_one_period(period_name)
        self._test_predicted(period_name)
        self._eval_predicted(date_start, date_end, period_name)
    
    def _merge_one_period(self, period_name):
        """
        åˆå¹¶æŒ‡å®šæœŸé—´çš„åº”ç”¨è¿‡æ»¤å™¨é€‰å®šå› å­ã€‚
        
        Args:
            period_name: æœŸé—´åç§°
            
        Returns:
            pd.DataFrame: è¯¥æœŸé—´çš„åˆå¹¶å¹³å‡å› å­
        """
        select_period_dir = self.select_period_dir
        merged_period_dir = self.merged_period_dir
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨
        output_path = merged_period_dir / f'avg_predict_{period_name}.parquet'
        
        # æœ€ç»ˆé€‰å®šå› å­çš„è·¯å¾„
        final_selected_factors_path = select_period_dir / 'final_selected_factors.csv'
        
        # æ£€æŸ¥æœ€ç»ˆé€‰å®šçš„å› å­æ˜¯å¦å­˜åœ¨
        if not os.path.exists(final_selected_factors_path):
            print(f"æœªæ‰¾åˆ°æœŸé—´ {period_name} çš„æœ€ç»ˆé€‰å®šå› å­")
            return None
        
        # åŠ è½½æœ€ç»ˆé€‰å®šçš„å› å­
        final_selected_factors = pd.read_csv(final_selected_factors_path)
        
        print(f"åŠ è½½äº† {len(final_selected_factors)} ä¸ªé€‰å®šçš„åº”ç”¨è¿‡æ»¤å™¨å› å­")
        
        # ä¸éœ€è¦è¿‡æ»¤åŸå§‹alphaï¼Œå› ä¸ºå¯ä»¥ç»Ÿä¸€å¤„ç†
        if final_selected_factors.empty:
            print(f"æœŸé—´ {period_name} æ²¡æœ‰é€‰å®šçš„å› å­")
            # åˆ›å»ºé›¶å› å­ä½œä¸ºå ä½ç¬¦
            price_path = self.config['price_path']
            fstart = self.config['fstart']
            price_data = pd.read_parquet(price_path)
            price_index = price_data.loc[fstart:].index
            zero_factor = pd.DataFrame(0, index=price_index, columns=price_data.columns)
            zero_factor.to_parquet(output_path)
            return None
        
        print(f"é€‰å®šçš„å› å­æ•°é‡: {len(final_selected_factors)}")
        
        # æŒ‰ç»„åˆ†ç»„å› å­
        grouped = final_selected_factors.groupby('group')
        factor_dict, weight_dict = self._process_groups_parallel(grouped, period_name, max_workers=self.max_workers)
        
        # è®¡ç®—è·¨ç»„çš„æ€»ä½“å¹³å‡å€¼
        factor_avg = compute_dataframe_dict_average(factor_dict, weight_dict)
        # ä½¿ç”¨ç»„æ ‡å‡†åŒ–å‡½æ•°æ¥æ ‡å‡†åŒ–æœ€ç»ˆç»“æœ
        factor_scaled = self.group_normalization_func(factor_avg).replace([-np.inf, np.inf], np.nan).fillna(0)
        
        # ä¿å­˜ç»“æœ
        factor_scaled.to_parquet(output_path)
        
        print(f"åˆå¹¶çš„åº”ç”¨è¿‡æ»¤å™¨å› å­å·²ä¿å­˜è‡³ {output_path}")
        
    def _process_groups_parallel(self, grouped, period_name, max_workers=None):
        """
        å¹¶è¡Œå¤„ç†æ‰€æœ‰ç»„
        
        Args:
            grouped: åˆ†ç»„åçš„æ•°æ®
            period_name: å‘¨æœŸåç§°
            max_workers: æœ€å¤§å·¥ä½œè¿›ç¨‹æ•°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é»˜è®¤å€¼(CPUæ ¸å¿ƒæ•°)
            
        Returns:
            tuple: (factor_dict, weight_dict) - å› å­å­—å…¸å’Œæƒé‡å­—å…¸
        """
        price_path = self.config['price_path']
        fstart = self.config['fstart']
        factor_dict, weight_dict = {}, {}
        
        # å‡†å¤‡å¹¶è¡Œå¤„ç†çš„å‚æ•°
        group_args = [(group_num, group_info, self.group_normalization_func, 
                       self.factor_normalization_func, price_path, fstart) 
                      for group_num, group_info in grouped]
        total_groups = len(group_args)
        
        if max_workers == 1 or max_workers is None:
            # å•è¿›ç¨‹é¡ºåºå¤„ç†
            with tqdm(total=total_groups, desc=f'å¤„ç† {period_name} çš„åº”ç”¨è¿‡æ»¤å™¨Groups [Single]') as pbar:
                for args in group_args:
                    group_num = args[0]
                    try:
                        group_num, group_avg = process_group_applied_filters(args)
                        factor_dict[group_num] = group_avg
                        weight_dict[group_num] = 1
                    except Exception as exc:
                        print(f'å¤„ç†åº”ç”¨è¿‡æ»¤å™¨ç»„ {group_num} æ—¶å‘ç”Ÿé”™è¯¯: {exc}')
                    finally:
                        pbar.update(1)
        else:
            # å¤šè¿›ç¨‹å¤„ç†
            with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
                future_to_group = {executor.submit(process_group_applied_filters, args): args[0] for args in group_args}
        
                with tqdm(total=total_groups, desc=f'å¤„ç† {period_name} çš„åº”ç”¨è¿‡æ»¤å™¨Groups [Multi]') as pbar:
                    for future in concurrent.futures.as_completed(future_to_group):
                        group_num = future_to_group[future]
                        try:
                            group_num, group_avg = future.result()
                            factor_dict[group_num] = group_avg
                            weight_dict[group_num] = 1
                        except Exception as exc:
                            print(f'å¤„ç†åº”ç”¨è¿‡æ»¤å™¨ç»„ {group_num} æ—¶å‘ç”Ÿé”™è¯¯: {exc}')
                        finally:
                            pbar.update(1)

        return factor_dict, weight_dict
    
    def _test_predicted(self, period_name):
        merged_period_dir = self.merged_period_dir
        
        process_name = None
        factor_data_dir = merged_period_dir
        result_dir = merged_period_dir
        params = self.config
        
        test_list = params['test_list']
        for test_info in test_list:
            mode = test_info['mode']
            test_name = test_info['test_name']
            if mode == 'test':
                test_class = FactorTesterByContinuous
            elif mode == 'trade':
                test_class = FactorTesterByDiscrete
            else:
                NotImplementedError()
        
            ft = test_class(process_name, None, factor_data_dir, test_name=test_name, result_dir=result_dir)
            ft.test_one_factor(f'avg_predict_{period_name}')
            
    def _eval_predicted(self, date_start, date_end, period_name):
        merged_period_dir = self.merged_period_dir
        max_workers = self.max_workers
        params = self.config
        test_list = params['test_list']
        eval_param = params['eval']
        price_path = self.config['price_path']
        factor_name = f'avg_predict_{period_name}'
        
        # å‡†å¤‡è¾“å…¥å‚æ•°åˆ—è¡¨
        input_params = []
        for test_info in test_list:
            input_params.append((
                test_info, 
                factor_name, 
                date_start, 
                date_end, 
                merged_period_dir, 
                eval_param, 
                price_path
            ))
        
        total_tasks = len(input_params)
        res_list = []
        
        # æ ¹æ®max_workerså†³å®šæ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹
        if max_workers == 1 or max_workers is None:
            # å•è¿›ç¨‹é¡ºåºæ‰§è¡Œï¼Œä½†æ˜¾ç¤ºè¿›åº¦æ¡
            for params in tqdm(input_params, desc="Processing tests", total=total_tasks):
                res_dict = process_test_info_applied_filters(*params)
                res_list.append(res_dict)
        else:
            # å¤šè¿›ç¨‹å¹¶è¡Œæ‰§è¡Œï¼Œä½¿ç”¨as_completedæ•è·è¿›åº¦
            with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_params = {executor.submit(process_test_info_applied_filters, *params): params for params in input_params}
                
                # ä½¿ç”¨as_completedè·å–å®Œæˆçš„ä»»åŠ¡å¹¶æ˜¾ç¤ºè¿›åº¦
                for future in tqdm(concurrent.futures.as_completed(future_to_params), total=total_tasks, desc="Processing tests"):
                    try:
                        res_dict = future.result()
                        res_list.append(res_dict)
                    except Exception as exc:
                        test_info = future_to_params[future][0]
                        print(f'Test {test_info["test_name"]} generated an exception: {exc}')
        
        # è½¬æ¢ä¸ºDataFrame
        res_df = pd.DataFrame(res_list)
        res_df.to_csv(merged_period_dir / 'evaluation.csv', index=None)
        

def process_test_info_applied_filters(test_info, factor_name, date_start, date_end, merged_period_dir, eval_param, price_path):
    mode = test_info['mode']
    test_name = test_info['test_name']
    eval_inputs = {
        "factor_name": factor_name,
        "date_start": date_start,
        "date_end": date_end,
        "data_date_start": date_start,
        "data_date_end": date_end,
        "process_name": '',
        "test_name": test_name,
        "tag_name": '',
        "data_dir": merged_period_dir / 'test' / test_name / 'data',
        "processed_data_dir": merged_period_dir,
        "valid_prop_thresh": eval_param['valid_prop_thresh'],
        "fee": eval_param['fee'],
        "price_data_path": price_path,
        "mode": mode, 
    }
    
    return eval_one_factor_one_period(**eval_inputs)


def example_usage():
    """
    ä½¿ç”¨ç¤ºä¾‹
    """
    # åˆå§‹åŒ–AppliedFiltersMerger
    afm = AppliedFiltersMerger(
        fac_merge_name='batch_till20_newma_batch_test_v3_icim_nsr22_m0',
        test_eval_filtered_alpha_name='corr_and_diffusion_v1',
        select_name='gt_nsr_ppt',
        filter_merge_name='m0',
        max_workers=4
    )
    
    # å¯¹å•ä¸ªæœŸé—´è¿›è¡Œåˆå¹¶
    from datetime import datetime
    afm.run_one_period(datetime(2015, 1, 1), datetime(2016, 1, 1))
    
    print("åº”ç”¨è¿‡æ»¤å™¨å› å­åˆå¹¶å®Œæˆ")


if __name__ == "__main__":
    example_usage()