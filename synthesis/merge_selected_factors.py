# -*- coding: utf-8 -*-
"""
Created on Sun Apr 27 14:22:49 2025

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
# %%
import os
import sys
from pathlib import Path
import pandas as pd
import numpy as np
from tqdm import tqdm
from typing import Union, Dict, Any
import yaml
from functools import partial
import concurrent.futures


# %% add sys path
file_path = Path(__file__).resolve()
file_dir = file_path.parents[0]
project_dir = file_path.parents[1]
sys.path.append(str(project_dir))


# %%
from utils.dirutils import load_path_config
from utils.datautils import compute_dataframe_dict_average
from utils.timeutils import period_shortcut
from test_and_eval.factor_tester import FactorTesterByContinuous, FactorTesterByDiscrete
from data_processing.ts_trans import ts_normalize
from test_and_eval.factor_evaluation import eval_one_factor_one_period


# %%
# =============================================================================
# def process_group(args):
#     """
#     å¤„ç†å•ä¸ªç»„çš„å‡½æ•°ï¼Œé€‚ç”¨äºå¹¶è¡Œæ‰§è¡Œ
#     
#     Args:
#         args: åŒ…å«æ‰€éœ€å‚æ•°çš„å…ƒç»„ (group_num, group_info, test_dir, normalization_func)
#         
#     Returns:
#         tuple: (group_num, group_scaled) - ç»„å·å’Œç»„çš„æ ‡å‡†åŒ–åçš„å¹³å‡å› å­
#     """
#     group_num, group_info, test_dir, normalization_func, price_path, fstart = args
#     
#     price_data = pd.read_parquet(price_path)
#     price_index = price_data.loc[fstart:].index
#     group_factor_dict, group_weight_dict = {}, {}
#     
#     # å¤„ç†ç»„å†…æ¯ä¸ªå› å­
#     for idx in group_info.index:
#         root_dir = 
#         tag_name = group_info.loc[idx, 'tag_name']
#         test_name = group_info.loc[idx, 'test_name']
#         process_name = group_info.loc[idx, 'process_name']
#         factor = group_info.loc[idx, 'factor']
#         direction = group_info.loc[idx, 'direction']
#         
#         # åŠ è½½ç¼©æ”¾å› å­
#         scaled_fac_path = test_dir / test_name / tag_name / process_name / 'data' / f'scaled_{factor}.parquet'
#         scaled_fac = pd.read_parquet(scaled_fac_path)
#         
#         # å­˜å‚¨å› å­åŠå…¶æƒé‡
#         group_factor_dict[idx] = (direction * scaled_fac).reindex(index=price_index).replace([-np.inf, np.inf], np.nan).fillna(0)
#         # if scaled_fac.count() / len(scaled_fac) < 0.5:
#         #     print(test_name, process_name, factor)
#         group_weight_dict[idx] = 1
#     
#     # è®¡ç®—ç»„å¹³å‡å€¼å¹¶æ ‡å‡†åŒ–
#     group_avg = compute_dataframe_dict_average(group_factor_dict, group_weight_dict)
#     group_scaled = normalization_func(group_avg).replace([-np.inf, np.inf], np.nan).fillna(0)
#     return group_num, group_scaled
# =============================================================================


def process_group(args):
    """
    å¤„ç†å•ä¸ªç»„çš„å‡½æ•°ï¼Œé€‚ç”¨äºå¹¶è¡Œæ‰§è¡Œ
    
    Args:
        args: åŒ…å«æ‰€éœ€å‚æ•°çš„å…ƒç»„ (group_num, group_info, test_dir, group_normalization_func, factor_normalization_func)
        
    Returns:
        tuple: (group_num, group_scaled) - ç»„å·å’Œç»„çš„æ ‡å‡†åŒ–åçš„å¹³å‡å› å­
    """
    group_num, group_info, test_dir, group_normalization_func, factor_normalization_func, price_path, fstart = args
    
    price_data = pd.read_parquet(price_path)
    price_index = price_data.loc[fstart:].index
    group_factor_dict, group_weight_dict = {}, {}
    
    # å¤„ç†ç»„å†…æ¯ä¸ªå› å­
    for idx in group_info.index:
        root_dir = group_info.loc[idx, 'root_dir']
        process_name = group_info.loc[idx, 'process_name']
        factor = group_info.loc[idx, 'factor']
        direction = group_info.loc[idx, 'direction']
        
        # åŠ è½½ç¼©æ”¾å› å­
        fac_path = Path(root_dir) / process_name / f'{factor}.parquet'
        fac = pd.read_parquet(fac_path)
        
        # ä½¿ç”¨å•å› å­æ ‡å‡†åŒ–å‡½æ•°
        scaled_fac = factor_normalization_func(fac)
        
        # å­˜å‚¨å› å­åŠå…¶æƒé‡
        group_factor_dict[idx] = (direction * scaled_fac).reindex(index=price_index).replace([-np.inf, np.inf], np.nan).fillna(0)
        group_weight_dict[idx] = 1
    
    # è®¡ç®—ç»„å¹³å‡å€¼å¹¶ä½¿ç”¨ç»„æ ‡å‡†åŒ–å‡½æ•°æ ‡å‡†åŒ–
    group_avg = compute_dataframe_dict_average(group_factor_dict, group_weight_dict)
    group_scaled = group_normalization_func(group_avg).replace([-np.inf, np.inf], np.nan).fillna(0)
    return group_num, group_scaled


class FactorMerger:
    
    def __init__(self, merge_name, select_name, max_workers=None):
        """
        åˆå§‹åŒ–FactorMergerï¼Œä½¿ç”¨é¡¹ç›®ç›®å½•å’Œé€‰æ‹©åç§°ã€‚
        
        Args:
            merge_name: åˆå¹¶é…ç½®åç§°
            select_name: é€‰æ‹©åç§°
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°
        """
        self.merge_name = merge_name
        self.select_name = select_name
        self.max_workers = max_workers
        
        # åŠ è½½è·¯å¾„é…ç½®
        self.path_config = load_path_config(project_dir)
        self.result_dir = Path(self.path_config['result'])
        self.param_dir = Path(self.path_config['param']) / 'merge_selected_factors'
        self.test_dir = self.result_dir / 'test'
        self.merged_dir = self.result_dir / 'merge_selected_factors' / f'{self.select_name}_{merge_name}'
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        config_path = self.param_dir / f'{merge_name}.yaml'
        self.config = self._load_config(config_path)
        
        self.select_dir = self.result_dir / 'select_factors' / self.select_name
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.merged_dir.mkdir(parents=True, exist_ok=True)
        
        self._init_utils()
        
    def _load_config(self, config_path: Union[str, Path]) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        å‚æ•°:
            config_path (str or Path): é…ç½®æ–‡ä»¶è·¯å¾„
            
        è¿”å›:
            Dict[str, Any]: é…ç½®å­—å…¸
        """
        config_path = Path(config_path)
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        return config
    
    def _init_utils(self):
        # ä»é…ç½®ä¸­è¯»å–ä¸¤ä¸ªä¸åŒçš„é¢„å¤„ç†å‚æ•°
        group_preprocess_params = self.config['group_preprocess_params']
        factor_preprocess_params = self.config['factor_preprocess_params']
        
        # åˆå§‹åŒ–ä¸¤ä¸ªä¸åŒçš„æ ‡å‡†åŒ–å‡½æ•°
        self.group_normalization_func = partial(ts_normalize, param=group_preprocess_params)
        self.factor_normalization_func = partial(ts_normalize, param=factor_preprocess_params)
        
    def run_one_period(self, date_start, date_end):
        # ç”ŸæˆæœŸé—´åç§°
        period_name = period_shortcut(date_start, date_end)
        
        # è®¾ç½®æ­¤æœŸé—´çš„ç›®å½•
        self.select_period_dir = self.select_dir / period_name
        self.merged_period_dir = self.merged_dir / period_name
        self.merged_period_dir.mkdir(parents=True, exist_ok=True)
        
        self._merge_one_period(period_name)
        self._test_predicted(period_name)
        self._eval_predicted(date_start, date_end, period_name)
    
    def _merge_one_period(self, period_name):
        """
        åˆå¹¶æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„å› å­ã€‚
        
        Args:
            date_start: å¼€å§‹æ—¥æœŸ
            date_end: ç»“æŸæ—¥æœŸ
            
        Returns:
            pd.DataFrame: è¯¥æœŸé—´çš„åˆå¹¶å¹³å‡å› å­
        """
        select_period_dir = self.select_period_dir
        merged_period_dir = self.merged_period_dir
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨
        output_path = merged_period_dir / f'avg_predict_{period_name}.parquet'
        # if os.path.exists(output_path):
        #     return
        
        # æœ€ç»ˆé€‰å®šå› å­çš„è·¯å¾„
        final_selected_factors_path = select_period_dir / 'final_selected_factors.csv'
        
        # æ£€æŸ¥æœ€ç»ˆé€‰å®šçš„å› å­æ˜¯å¦å­˜åœ¨
        if not os.path.exists(final_selected_factors_path):
            print(f"æœªæ‰¾åˆ°æœŸé—´ {period_name} çš„æœ€ç»ˆé€‰å®šå› å­")
            return None
        
        # åŠ è½½æœ€ç»ˆé€‰å®šçš„å› å­
        final_selected_factors = pd.read_csv(final_selected_factors_path)
        
        # æŒ‰ç»„åˆ†ç»„å› å­
        grouped = final_selected_factors.groupby('group')
        factor_dict, weight_dict = self._process_groups_parallel(grouped, period_name, max_workers=self.max_workers)
        
        # è®¡ç®—è·¨ç»„çš„æ€»ä½“å¹³å‡å€¼
        factor_avg = compute_dataframe_dict_average(factor_dict, weight_dict)
        # ä½¿ç”¨ç»„æ ‡å‡†åŒ–å‡½æ•°æ¥æ ‡å‡†åŒ–æœ€ç»ˆç»“æœ
        factor_scaled = self.group_normalization_func(factor_avg).replace([-np.inf, np.inf], np.nan).fillna(0)
        
        # ä¿å­˜ç»“æœ
        factor_scaled.to_parquet(output_path)
        
        print(f"åˆå¹¶å› å­å·²ä¿å­˜è‡³ {output_path}")
        
    def _process_groups_parallel(self, grouped, period_name, max_workers=None):
        """
        å¹¶è¡Œå¤„ç†æ‰€æœ‰ç»„
        
        Args:
            grouped: åˆ†ç»„åçš„æ•°æ®
            period_name: å‘¨æœŸåç§°
            max_workers: æœ€å¤§å·¥ä½œè¿›ç¨‹æ•°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é»˜è®¤å€¼(CPUæ ¸å¿ƒæ•°)
            
        Returns:
            tuple: (factor_dict, weight_dict) - å› å­å­—å…¸å’Œæƒé‡å­—å…¸
        """
        price_path = self.config['price_path']
        fstart = self.config['fstart']
        factor_dict, weight_dict = {}, {}
        
        # å‡†å¤‡å¹¶è¡Œå¤„ç†çš„å‚æ•°ï¼Œç°åœ¨ä¼ å…¥ä¸¤ä¸ªæ ‡å‡†åŒ–å‡½æ•°
        group_args = [(group_num, group_info, self.test_dir, self.group_normalization_func, 
                       self.factor_normalization_func, price_path, fstart) 
                      for group_num, group_info in grouped]
        total_groups = len(group_args)
        
        if max_workers == 1 or max_workers is None:
            # å•è¿›ç¨‹é¡ºåºå¤„ç†
            with tqdm(total=total_groups, desc=f'å¤„ç† {period_name} çš„Groups') as pbar:
                for args in group_args:
                    group_num = args[0]
                    try:
                        group_num, group_avg = process_group(args)
                        factor_dict[group_num] = group_avg
                        weight_dict[group_num] = 1
                    except Exception as exc:
                        print(f'å¤„ç†ç»„ {group_num} æ—¶å‘ç”Ÿé”™è¯¯: {exc}')
                    finally:
                        pbar.update(1)
        else:
            # å¤šè¿›ç¨‹å¤„ç†
            with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
                future_to_group = {executor.submit(process_group, args): args[0] for args in group_args}
        
                with tqdm(total=total_groups, desc=f'å¤„ç† {period_name} çš„Groups') as pbar:
                    for future in concurrent.futures.as_completed(future_to_group):
                        group_num = future_to_group[future]
                        try:
                            group_num, group_avg = future.result()
                            factor_dict[group_num] = group_avg
                            weight_dict[group_num] = 1
                        except Exception as exc:
                            print(f'å¤„ç†ç»„ {group_num} æ—¶å‘ç”Ÿé”™è¯¯: {exc}')
                        finally:
                            pbar.update(1)

        return factor_dict, weight_dict
    
    def _test_predicted(self, period_name):
        merged_period_dir = self.merged_period_dir
        
        process_name = None
        factor_data_dir = merged_period_dir
        result_dir = merged_period_dir
        params = self.config
        
        test_list = params['test_list']
        for test_info in test_list:
            mode = test_info['mode']
            test_name = test_info['test_name']
            if mode == 'test':
                test_class = FactorTesterByContinuous
            elif mode == 'trade':
                test_class = FactorTesterByDiscrete
            else:
                NotImplementedError()
        
            ft = test_class(process_name, None, factor_data_dir, test_name=test_name, result_dir=result_dir)
            ft.test_one_factor(f'avg_predict_{period_name}')
            
    def _eval_predicted(self, date_start, date_end, period_name):
        merged_period_dir = self.merged_period_dir
        max_workers = self.max_workers
        params = self.config
        test_list = params['test_list']
        eval_param = params['eval']
        price_path = self.config['price_path']
        factor_name = f'avg_predict_{period_name}'
        
        # å‡†å¤‡è¾“å…¥å‚æ•°åˆ—è¡¨
        input_params = []
        for test_info in test_list:
            input_params.append((
                test_info, 
                factor_name, 
                date_start, 
                date_end, 
                merged_period_dir, 
                eval_param, 
                price_path
            ))
        
        total_tasks = len(input_params)
        res_list = []
        
        # æ ¹æ®max_workerså†³å®šæ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹
        if max_workers == 1 or max_workers is None:
            # å•è¿›ç¨‹é¡ºåºæ‰§è¡Œï¼Œä½†æ˜¾ç¤ºè¿›åº¦æ¡
            for params in tqdm(input_params, desc="Processing tests", total=total_tasks):
                res_dict = process_test_info(*params)
                res_list.append(res_dict)
        else:
            # å¤šè¿›ç¨‹å¹¶è¡Œæ‰§è¡Œï¼Œä½¿ç”¨as_completedæ•è·è¿›åº¦
            with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_params = {executor.submit(process_test_info, *params): params for params in input_params}
                
                # ä½¿ç”¨as_completedè·å–å®Œæˆçš„ä»»åŠ¡å¹¶æ˜¾ç¤ºè¿›åº¦
                for future in tqdm(concurrent.futures.as_completed(future_to_params), total=total_tasks, desc="Processing tests"):
                    try:
                        res_dict = future.result()
                        res_list.append(res_dict)
                    except Exception as exc:
                        test_info = future_to_params[future][0]
                        print(f'Test {test_info["test_name"]} generated an exception: {exc}')
        
        # è½¬æ¢ä¸ºDataFrame
        res_df = pd.DataFrame(res_list)
        res_df.to_csv(merged_period_dir / 'evaluation.csv', index=None)
        

def process_test_info(test_info, factor_name, date_start, date_end, merged_period_dir, eval_param, price_path):
    mode = test_info['mode']
    test_name = test_info['test_name']
    eval_inputs = {
        "factor_name": factor_name,
        "date_start": date_start,
        "date_end": date_end,
        "data_date_start": date_start,
        "data_date_end": date_end,
        "process_name": '',
        "test_name": test_name,
        "tag_name": '',
        "data_dir": merged_period_dir / 'test' / test_name / 'data',
        "processed_data_dir": merged_period_dir,
        "valid_prop_thresh": eval_param['valid_prop_thresh'],
        "fee": eval_param['fee'],
        "price_data_path": price_path,
        "mode": mode, 
    }
    
    return eval_one_factor_one_period(**eval_inputs)