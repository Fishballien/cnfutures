# -*- coding: utf-8 -*-
"""
Created on Tue Dec 17 10:45:55 2024

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
# %% imports
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.dates import DateFormatter
import matplotlib.ticker as ticker
import numpy as np
from functools import partial
from tqdm import tqdm
import pickle
import seaborn as sns


from utils.datautils import align_and_sort_columns
from utils.market import index_to_futures
# from trans_operators.format import to_float32


from utils.timeutils import parse_time_string
from utils.trade_rules import *
from data_processing.ts_trans import *
from test_and_eval.factor_tester import FactorTesterByDiscrete
from test_and_eval.factor_evaluation import eval_one_factor_one_period_net_public


# %%
sl_tp_name = "v0"
model_name = 'avg_agg_250218_3_fix_tfe_by_trade_net_v4'
factor_name = f'predict_{model_name}'
factor_dir = Path(rf'D:\mnt\CNIndexFutures\timeseries\factor_test\results\model\{model_name}\predict')
direction = 1

# factor_name = 'LargeOrderAmountByValue_p1.0_v40000-wavg_imb04_dpall-mean_w30min'
# direction = -1
# factor_dir = Path(r'D:/mnt/CNIndexFutures/timeseries/factor_test/sample_data/factors/low_freq')


# %%
test_name = 'traded_futtwap_sp1min_s240d_icim_v6_noscale'
price_name = 't1min_fq1min_dl1min'

scale_method = 'minmax_scale'
scale_window = '240d'
scale_quantile = 0.02
sp = '1min'

trade_rule_name = 'trade_rule_by_trigger_v5'
trade_rule_param = {
    'openthres': 0.8,
    'closethres': 0,
    }

fee = 0.00024

sl_list = [100, 0.0025, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05]
tp_list = [100, 0.0025, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05]

# sl_list = [100, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05]
# tp_list = [100, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05]

date_start = '20160101'
date_end = '20250101'


# %%
fut_dir = Path('/mnt/data1/future_twap')
analysis_dir = Path(r'D:\mnt\CNIndexFutures\timeseries\factor_test\results\analysis\sl_tp')
pos_dir = analysis_dir / 'pos' / factor_name / trade_rule_name / sl_tp_name
pos_dir.mkdir(parents=True, exist_ok=True)
test_dir = analysis_dir / 'test' / factor_name / trade_rule_name / sl_tp_name
test_dir.mkdir(parents=True, exist_ok=True)
summary_dir = analysis_dir / 'summary' / factor_name / trade_rule_name / sl_tp_name
summary_dir.mkdir(parents=True, exist_ok=True)


# %%
factor_data = pd.read_parquet(factor_dir / f'{factor_name}.parquet')
price_data = pd.read_parquet(fut_dir / f'{price_name}.parquet')
factor_data = factor_data.rename(columns=index_to_futures)[['IC', 'IF', 'IM']]
factor_data, price_data = align_and_sort_columns([factor_data, price_data])

price_data = price_data.loc[factor_data.index.min():factor_data.index.max()] # æŒ‰factorå¤´å°¾æˆªå–
factor_data = factor_data.reindex(price_data.index) # æŒ‰twap reindexï¼Œç¡®ä¿ç­‰é•¿


# %%
scale_func = globals()[scale_method]
scale_step = int(parse_time_string(scale_window) / parse_time_string(sp))
# factor_scaled = ts_quantile_scale(factor, window=scale_step, quantile=scale_quantile)
if scale_method in ['minmax_scale', 'minmax_scale_separate']:
    factor_scaled = scale_func(factor_data, window=scale_step, quantile=scale_quantile)
elif scale_method in ['minmax_scale_adj_by_his_rtn', 'zscore_adj_by_his_rtn_and_minmax']:
    factor_scaled = scale_func(factor, rtn_1p, window=scale_step, rtn_window=pp_by_sp, quantile=scale_quantile)
elif scale_method in ['rolling_percentile']:
    factor_scaled = scale_func(factor, window=scale_step)
elif scale_method in ['percentile_adj_by_his_rtn']:
    factor_scaled = scale_func(factor, rtn_1p, window=scale_step, rtn_window=pp_by_sp)

factor_scaled = (factor_scaled - 0.5) * 2 * direction


# %%
# =============================================================================
# for sl in tqdm(sl_list, desc='sl'):
#     for tp in tp_list:
#         trade_rule_param_spec = {k: v for k, v in trade_rule_param.items()}
#         trade_rule_param_spec['stoploss_pct'] = sl
#         trade_rule_param_spec['takeprofit_pct'] = tp
#         trade_rule_func = partial(globals()[trade_rule_name], **trade_rule_param_spec)
#         actual_pos = factor_scaled.apply(lambda col: trade_rule_func(col.values, price_data[col.name].shift(2).values), axis=0)
#         file_name = f'sl{sl}_tp{tp}'
#         actual_pos.to_parquet(pos_dir / f'{file_name}.parquet')
# 
# =============================================================================

# %%
# =============================================================================
# tester = FactorTesterByDiscrete(None, None, pos_dir, test_name=test_name, 
#                                 result_dir=test_dir)
# tester.test_multi_factors()
# =============================================================================


# %%
# =============================================================================
# test_data_dir = test_dir / 'test' / test_name / 'data'
# 
# res_list = []
# for sl in sl_list:
#     for tp in tp_list:
#         res_info = {
#             'sl': sl, 
#             'tp': tp, 
#             }
#         pred_name = f'sl{sl}_tp{tp}'
#         res_dict = eval_one_factor_one_period_net_public(
#             pred_name, res_info, test_data_dir, date_start, date_end, fee)
#         
#         res_list.append(res_dict)
#         
# res_df = pd.DataFrame(res_list)
# =============================================================================


# %%
# =============================================================================
# import os
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns
# 
# # å‡è®¾res_dfå·²ç»åŠ è½½åˆ°ç¯å¢ƒä¸­
# # æå– x, y å’Œ heatmap æŒ‡æ ‡
# x = "sl"
# y = "tp"
# heatmap_metrics = [col for col in res_df.columns if col not in [x, y]]
# 
# # éå†æ‰€æœ‰æŒ‡æ ‡ç»˜åˆ¶heatmap
# for metric in heatmap_metrics:
#     pivot_table = res_df.pivot(index=y, columns=x, values=metric)
# 
#     plt.figure(figsize=(10, 8))
#     sns.heatmap(pivot_table, annot=True, fmt=".2f", cmap="coolwarm", cbar=True)
#     plt.title(f"Heatmap of {metric}")
#     plt.xlabel(x)
#     plt.ylabel(y)
# 
#     # ä¿å­˜å›¾ç‰‡
#     img_path = os.path.join(summary_dir, f"heatmap_{metric}.png")
#     plt.savefig(img_path, dpi=300, bbox_inches="tight")
#     plt.close()
# 
# # æ˜¾ç¤ºå®Œæˆæ¶ˆæ¯
# summary_dir
# =============================================================================


# %%
test_data_dir = test_dir / 'test' / test_name / 'data'

net_list = []
for sl in sl_list:
    for tp in tp_list:
        res_info = {
            'sl': sl, 
            'tp': tp, 
            }
        pred_name = f'sl{sl}_tp{tp}'
        test_data = {}
        for data_type in ('gpd', 'hsr'):
            data_path = test_data_dir / f'{data_type}_{pred_name}.pkl'
            with open(data_path, 'rb') as f:
                test_data[data_type] = pickle.load(f)
                
        df_gp = test_data['gpd']['all']
        df_hsr = test_data['hsr']['all']
        
        net = (df_gp['return'] - fee * df_hsr['avg']).fillna(0)
        
        net_list.append(net)
        
# å°† net_list è½¬æ¢ä¸º DataFrame
# æ¯ä¸ª net_list å…ƒç´ æ˜¯ä¸€ä¸ª pandas Seriesï¼Œæ‰€ä»¥æˆ‘ä»¬å°†å®ƒä»¬ç»„åˆæˆä¸€ä¸ª DataFrame
net_df = pd.DataFrame({f'net_{i}': net for i, net in enumerate(net_list)})

# è®¡ç®—ä¸¤ä¸¤ä¹‹é—´çš„ç›¸å…³æ€§
corr_matrix = net_df.corr()

# ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', fmt='.2f', 
            xticklabels=False, yticklabels=False)

# æ·»åŠ æ ‡é¢˜
plt.title(f'Correlation Heatmap for {model_name} {trade_rule_name}')

# è°ƒæ•´å›¾åƒå¸ƒå±€ï¼Œé¿å…æ ‡ç­¾é®æŒ¡
plt.tight_layout()

# ä¿å­˜å›¾åƒ
corr_img_filename = summary_dir / 'correlation_heatmap.png'
plt.savefig(corr_img_filename)
plt.show()
plt.close()  # å…³é—­å½“å‰å›¾åƒï¼Œé˜²æ­¢é‡å 


# %%
test_data_dir = test_dir / 'test' / test_name / 'data'
net_list = []
# ä¿å­˜æ¯ä¸ªç½‘æ ¼å¯¹åº”çš„slå’Œtpå€¼
param_labels = []

for sl in sl_list:
    for tp in tp_list:
        res_info = {
            'sl': sl, 
            'tp': tp, 
            }
        param_labels.append(f'sl{sl}_tp{tp}')
        pred_name = f'sl{sl}_tp{tp}'
        test_data = {}
        for data_type in ('gpd', 'hsr'):
            data_path = test_data_dir / f'{data_type}_{pred_name}.pkl'
            with open(data_path, 'rb') as f:
                test_data[data_type] = pickle.load(f)
                
        df_gp = test_data['gpd']['all']
        df_hsr = test_data['hsr']['all']
        
        net = (df_gp['return'] - fee * df_hsr['avg']).fillna(0)
        
        net_list.append(net)
        
# å°† net_list è½¬æ¢ä¸º DataFrameï¼Œå¹¶ä½¿ç”¨å‚æ•°æ ‡ç­¾ä½œä¸ºåˆ—å
net_df = pd.DataFrame({label: net for label, net in zip(param_labels, net_list)})

# è®¡ç®—ä¸¤ä¸¤ä¹‹é—´çš„ç›¸å…³æ€§
corr_matrix = net_df.corr()

# åˆ›å»ºä¸€ä¸ªæ›´å¤§çš„å›¾ï¼Œä»¥ä¾¿æœ‰è¶³å¤Ÿç©ºé—´æ˜¾ç¤ºæ ‡ç­¾
plt.figure(figsize=(16, 14))

# ç»˜åˆ¶çƒ­åŠ›å›¾ï¼Œè¿™æ¬¡åŒ…å«æ ‡ç­¾
ax = sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', fmt='.2f',
               xticklabels=param_labels, yticklabels=param_labels)

# è®¾ç½®æ ‡ç­¾æ—‹è½¬è§’åº¦ï¼Œæé«˜å¯è¯»æ€§
plt.xticks(rotation=90)
plt.yticks(rotation=0)

# æ·»åŠ ç½‘æ ¼çº¿æ¥åˆ†éš”ä¸åŒçš„slåŒºåŸŸ
sl_count = len(sl_list)
tp_count = len(tp_list)
total_count = sl_count * tp_count

# æ·»åŠ å‚ç›´å’Œæ°´å¹³åˆ†éš”çº¿ä»¥åŒºåˆ†ä¸åŒçš„slç»„
for i in range(1, sl_count):
    plt.axhline(y=i*tp_count, color='black', linestyle='-', linewidth=2)
    plt.axvline(x=i*tp_count, color='black', linestyle='-', linewidth=2)

# æ·»åŠ æ ‡é¢˜å’Œæ ‡ç­¾
plt.title(f'Correlation Heatmap for {model_name} {trade_rule_name}', fontsize=16)
plt.xlabel('Parameter Combinations', fontsize=14)
plt.ylabel('Parameter Combinations', fontsize=14)


# æ·»åŠ slå’Œtpçš„åŒºåŸŸæ ‡æ³¨
# ä¸ºæ¯ä¸ªslç»„æ·»åŠ æ–‡æœ¬æ ‡ç­¾
for i, sl in enumerate(sl_list):
    # ä¸ºçƒ­åŠ›å›¾è¾¹ç¼˜æ·»åŠ slç»„æ ‡ç­¾
    plt.text(-0.05, i*tp_count + tp_count/2, f'SL={sl}', 
             horizontalalignment='right', verticalalignment='center',
             fontsize=12, fontweight='bold')
    
    plt.text(i*tp_count + tp_count/2, -0.05, f'SL={sl}', 
             horizontalalignment='center', verticalalignment='top',
             fontsize=12, fontweight='bold', rotation=90)

# è°ƒæ•´å›¾åƒå¸ƒå±€ï¼Œé¿å…æ ‡ç­¾é®æŒ¡
plt.tight_layout()

# ä¿å­˜å›¾åƒ
corr_img_filename = summary_dir / 'correlation_heatmap_annotated.png'
plt.savefig(corr_img_filename, bbox_inches='tight', dpi=300)
plt.show()
plt.close()  # å…³é—­å½“å‰å›¾åƒï¼Œé˜²æ­¢é‡å 

# å¦‚æœéœ€è¦æ›´æ¸…æ™°åœ°æŸ¥çœ‹ä¸åŒå‚æ•°ç»„åˆçš„ç›¸å…³æ€§ï¼Œå¯ä»¥æ·»åŠ å¦ä¸€ä¸ªçƒ­åŠ›å›¾
# è¿™ä¸ªçƒ­åŠ›å›¾ä½¿ç”¨å¹³å‡ç›¸å…³æ€§æ¥æ˜¾ç¤ºä¸åŒslç»„ä¹‹é—´çš„å…³ç³»
sl_groups = []
for i, sl in enumerate(sl_list):
    start_idx = i * tp_count
    end_idx = start_idx + tp_count
    sl_group = corr_matrix.iloc[start_idx:end_idx, start_idx:end_idx].mean().mean()
    sl_groups.append((sl, sl_group))

# åˆ›å»ºä¸€ä¸ªæ–°çš„çƒ­åŠ›å›¾ï¼Œæ˜¾ç¤ºä¸åŒslç»„ä¹‹é—´çš„å¹³å‡ç›¸å…³æ€§
sl_corr = np.zeros((sl_count, sl_count))
for i in range(sl_count):
    for j in range(sl_count):
        start_i, end_i = i * tp_count, (i + 1) * tp_count
        start_j, end_j = j * tp_count, (j + 1) * tp_count
        sl_corr[i, j] = corr_matrix.iloc[start_i:end_i, start_j:end_j].mean().mean()

plt.figure(figsize=(10, 8))
ax = sns.heatmap(sl_corr, annot=True, cmap='coolwarm', fmt='.2f',
               xticklabels=[f'SL={sl}' for sl in sl_list],
               yticklabels=[f'SL={sl}' for sl in sl_list])

plt.title(f'Average Correlation Between SL Groups for {model_name} {trade_rule_name}', fontsize=14)
plt.tight_layout()

# ä¿å­˜å›¾åƒ
sl_corr_img_filename = summary_dir / 'sl_group_correlation_heatmap.png'
plt.savefig(sl_corr_img_filename, bbox_inches='tight', dpi=300)
plt.show()
plt.close()