# -*- coding: utf-8 -*-
"""
Created on Mon Apr 21 13:27:45 2025

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
# %%
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.gridspec import GridSpec
from pathlib import Path


# %% add sys path
file_path = Path(__file__).resolve()
file_dir = file_path.parents[0]
project_dir = file_path.parents[2]
sys.path.append(str(project_dir))


# %%
from utils.dirutils import load_path_config


# %%
eval_name = 'basis_pct_250416_org_batch_250419_batch_test_v1'
period = '160101_250101'


# %%
path_config = load_path_config(project_dir)
result_dir = Path(path_config['result'])
eval_dir = result_dir / 'factor_evaluation'
analysis_dir = result_dir / 'analysis/eval_analysis'
summary_dir = analysis_dir / f'{eval_name}/factor_eval_{period}'
 

# %%
path = eval_dir / eval_name / f'factor_eval_{period}.csv'
eval_res = pd.read_csv(path)
eval_res['final_path'] = eval_res['process_name'].apply(lambda x: x.split('/')[1])
eval_res['org_fac'] = eval_res['factor'].apply(lambda x: x.split('-', 1)[0])
eval_res['trans_fac'] = eval_res['factor'].apply(lambda x: x.split('-', 1)[1])


# %%
# è®¾ç½®å…¨å±€å˜é‡
METRICS_DICT = {
    'net_sharpe_ratio': 'Net Sharpe Ratio',
    'net_calmar_ratio': 'Net Calmar Ratio',
    'net_sortino_ratio': 'Net Sortino Ratio',
    'net_return_annualized': 'Net Return (Annualized)',
    'net_max_dd': 'Net Maximum Drawdown',
    'net_sharpe_ratio_long_only': 'Net Sharpe Ratio (Long Only)',
    'net_sharpe_ratio_short_only': 'Net Sharpe Ratio (Short Only)'
}

COLOR_SCHEME = {
    'heat_main': 'RdYlBu_r',
    'heat_secondary': 'viridis',
    'box': 'Set3',
    'line': 'tab10'
}

def setup_output_directory(summary_dir, org_fac):
    """è®¾ç½®è¾“å‡ºç›®å½•"""
    base_dir = Path(summary_dir)
    base_dir.mkdir(exist_ok=True, parents=True)
    
    org_fac_dir = base_dir / org_fac
    org_fac_dir.mkdir(exist_ok=True)
    
    return org_fac_dir

def run_analysis(df, summary_dir, metrics=None, percentiles=None):
    """è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
    if metrics is None:
        metrics = ['net_sharpe_ratio']
    
    if percentiles is None:
        percentiles = [90]
    
    # æŒ‰org_facåˆ†ç»„
    org_facs = df['org_fac'].unique()
    
    for org_fac in org_facs:
        print(f"åˆ†æ org_fac: {org_fac}")
        
        # ç­›é€‰å½“å‰org_facçš„æ•°æ®
        org_fac_data = df[df['org_fac'] == org_fac].copy()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = setup_output_directory(summary_dir, org_fac)
        
        # ä¸ºæ¯ä¸ªæŒ‡æ ‡ç”Ÿæˆåˆ†æ
        for metric in metrics:
            for percentile in percentiles:
                analyze_single_metric(org_fac_data, metric, percentile, output_dir)
        
        # æ¯”è¾ƒç­–ç•¥ï¼ˆåªéœ€è¿è¡Œä¸€æ¬¡ï¼‰
        compare_strategies(org_fac_data, output_dir)

def analyze_single_metric(data, metric, percentile, output_dir):
    """åˆ†æå•ä¸ªæŒ‡æ ‡"""
    print(f"  åˆ†ææŒ‡æ ‡: {metric}, åˆ†ä½æ•°: {percentile}")
    
    # æå–å”¯ä¸€è·¯å¾„å’Œæµ‹è¯•åç§°
    final_paths = sorted(data['final_path'].unique())
    test_names = sorted(data['test_name'].unique())
    
    # 1. ç”Ÿæˆçƒ­åŠ›å›¾
    generate_heatmaps(data, metric, percentile, final_paths, test_names, output_dir)
    
    # 2. ç”Ÿæˆåˆ†å¸ƒç®±çº¿å›¾
    generate_distribution_plots(data, metric, final_paths, test_names, output_dir)
    
    # 3. ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡è¡¨
    generate_summary_table(data, metric, percentile, output_dir)

def generate_heatmaps(data, metric, percentile, final_paths, test_names, output_dir):
    """ç”Ÿæˆçƒ­åŠ›å›¾ï¼šå‡å€¼ã€åˆ†ä½æ•°ã€æœ€å¤§å€¼ã€æœ€å°å€¼"""
    fig = plt.figure(figsize=(20, 16))
    gs = GridSpec(2, 2, figure=fig)
    
    # è®¡ç®—ç»Ÿè®¡é‡
    pivot_mean = data.pivot_table(values=metric, index='final_path', columns='test_name', aggfunc='mean')
    pivot_percentile_high = data.pivot_table(values=metric, index='final_path', columns='test_name', 
                                           aggfunc=lambda x: np.percentile(x, percentile))
    pivot_percentile_low = data.pivot_table(values=metric, index='final_path', columns='test_name', 
                                          aggfunc=lambda x: np.percentile(x, 100-percentile))
    pivot_max = data.pivot_table(values=metric, index='final_path', columns='test_name', aggfunc='max')
    pivot_min = data.pivot_table(values=metric, index='final_path', columns='test_name', aggfunc='min')
    
    # ç¡®ä¿ä¸€è‡´çš„é¡ºåº
    pivot_mean = pivot_mean.reindex(index=final_paths, columns=test_names)
    pivot_percentile_high = pivot_percentile_high.reindex(index=final_paths, columns=test_names)
    pivot_percentile_low = pivot_percentile_low.reindex(index=final_paths, columns=test_names)
    pivot_max = pivot_max.reindex(index=final_paths, columns=test_names)
    pivot_min = pivot_min.reindex(index=final_paths, columns=test_names)
    
    # åˆ›å»ºçƒ­åŠ›å›¾
    ax1 = fig.add_subplot(gs[0, 0])
    sns.heatmap(pivot_mean, annot=True, fmt='.1f', cmap=COLOR_SCHEME['heat_main'], ax=ax1, cbar_kws={'label': 'Mean'})
    ax1.set_title(f'Mean {METRICS_DICT.get(metric, metric)}')
    ax1.set_xlabel('Test Name')
    ax1.set_ylabel('Final Path')
    
    ax2 = fig.add_subplot(gs[0, 1])
    sns.heatmap(pivot_percentile_high, annot=True, fmt='.1f', cmap=COLOR_SCHEME['heat_main'], ax=ax2, cbar_kws={'label': f'{percentile}th Percentile'})
    ax2.set_title(f'{percentile}th Percentile {METRICS_DICT.get(metric, metric)}')
    ax2.set_xlabel('Test Name')
    ax2.set_ylabel('Final Path')
    
    ax3 = fig.add_subplot(gs[1, 0])
    sns.heatmap(pivot_max, annot=True, fmt='.1f', cmap=COLOR_SCHEME['heat_main'], ax=ax3, cbar_kws={'label': 'Maximum'})
    ax3.set_title(f'Maximum {METRICS_DICT.get(metric, metric)}')
    ax3.set_xlabel('Test Name')
    ax3.set_ylabel('Final Path')
    
    ax4 = fig.add_subplot(gs[1, 1])
    sns.heatmap(pivot_min, annot=True, fmt='.1f', cmap=COLOR_SCHEME['heat_main'], ax=ax4, cbar_kws={'label': 'Minimum'})
    ax4.set_title(f'Minimum {METRICS_DICT.get(metric, metric)}')
    ax4.set_xlabel('Test Name')
    ax4.set_ylabel('Final Path')
    
    plt.tight_layout()
    plt.savefig(output_dir / f'heatmaps_{metric}_pct{percentile}.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # ä¿å­˜æ•°æ®åˆ°CSV
    pivot_mean.to_csv(output_dir / f'heatmap_mean_{metric}.csv')
    pivot_percentile_high.to_csv(output_dir / f'heatmap_percentile_{percentile}_{metric}.csv')
    pivot_percentile_low.to_csv(output_dir / f'heatmap_percentile_{100-percentile}_{metric}.csv')
    pivot_max.to_csv(output_dir / f'heatmap_max_{metric}.csv')
    pivot_min.to_csv(output_dir / f'heatmap_min_{metric}.csv')

def generate_distribution_plots(data, metric, final_paths, test_names, output_dir):
    """ç”Ÿæˆåˆ†å¸ƒå›¾ï¼Œä½¿ç”¨æ›´ç´§å‡‘çš„æ–¹å¼å±•ç¤º"""
    # 1. æ¯ä¸ªfinal_pathçš„æ‰€æœ‰test_nameçš„åˆ†å¸ƒ
    plt.figure(figsize=(12, 8))
    
    # æŒ‰final_pathåˆ†ç»„ç»˜åˆ¶å°æç´å›¾
    ax = sns.violinplot(x='final_path', y=metric, data=data, inner='box', 
                       palette=sns.color_palette(COLOR_SCHEME['box'], len(final_paths)))
    
    ax.set_title(f'Distribution of {METRICS_DICT.get(metric, metric)} by Final Path')
    ax.set_xlabel('Final Path')
    ax.set_ylabel(METRICS_DICT.get(metric, metric))
    plt.xticks(rotation=45, ha='right')
    
    plt.tight_layout()
    plt.savefig(output_dir / f'dist_by_final_path_{metric}.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. æ¯ä¸ªtest_nameçš„æ‰€æœ‰final_pathçš„åˆ†å¸ƒ
    plt.figure(figsize=(12, 8))
    
    ax = sns.violinplot(x='test_name', y=metric, data=data, inner='box', 
                      palette=sns.color_palette(COLOR_SCHEME['box'], len(test_names)))
    
    ax.set_title(f'Distribution of {METRICS_DICT.get(metric, metric)} by Test Name')
    ax.set_xlabel('Test Name')
    ax.set_ylabel(METRICS_DICT.get(metric, metric))
    plt.xticks(rotation=45, ha='right')
    
    plt.tight_layout()
    plt.savefig(output_dir / f'dist_by_test_name_{metric}.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. å¦‚æœç»„åˆæ•°é‡ä¸å¤ªå¤šï¼Œåˆ™ç”»å‡ºæ¯ä¸ªç»„åˆçš„ç®±çº¿å›¾
    if len(final_paths) * len(test_names) <= 20:
        # åˆ›å»ºç»„åˆåç§°
        data['combo'] = data['final_path'] + ' | ' + data['test_name']
        
        plt.figure(figsize=(14, 8))
        
        ax = sns.boxplot(x='combo', y=metric, data=data, 
                       palette=sns.color_palette(COLOR_SCHEME['box'], len(data['combo'].unique())))
        
        ax.set_title(f'Distribution of {METRICS_DICT.get(metric, metric)} by Combination')
        ax.set_xlabel('Final Path | Test Name')
        ax.set_ylabel(METRICS_DICT.get(metric, metric))
        plt.xticks(rotation=90)
        
        plt.tight_layout()
        plt.savefig(output_dir / f'dist_by_combo_{metric}.png', dpi=300, bbox_inches='tight')
        plt.close()
    else:
        # å¦‚æœç»„åˆå¤ªå¤šï¼Œå°±ç”»å‡ºtop5å’Œbottom5çš„ç»„åˆ
        combo_stats = data.groupby(['final_path', 'test_name'])[metric].mean().reset_index()
        combo_stats['combo'] = combo_stats['final_path'] + ' | ' + combo_stats['test_name']
        
        # è·å–top5å’Œbottom5
        top5 = combo_stats.nlargest(5, metric)
        bottom5 = combo_stats.nsmallest(5, metric)
        extremes = pd.concat([top5, bottom5])
        
        # ç­›é€‰æ•°æ®
        extreme_combos = list(extremes['combo'].unique())
        data['combo'] = data['final_path'] + ' | ' + data['test_name']
        filtered_data = data[data['combo'].isin(extreme_combos)]
        
        plt.figure(figsize=(14, 8))
        
        ax = sns.boxplot(x='combo', y=metric, data=filtered_data, 
                       palette=sns.color_palette(COLOR_SCHEME['box'], 10))
        
        ax.set_title(f'Distribution of {METRICS_DICT.get(metric, metric)} - Top 5 & Bottom 5 Combinations')
        ax.set_xlabel('Final Path | Test Name')
        ax.set_ylabel(METRICS_DICT.get(metric, metric))
        plt.xticks(rotation=90)
        
        # æ·»åŠ æ ‡è®°è¡¨ç¤ºtopå’Œbottom
        for i, combo in enumerate(ax.get_xticklabels()):
            combo_text = combo.get_text()
            if combo_text in top5['combo'].values:
                ax.get_xticklabels()[i].set_color('green')
            else:
                ax.get_xticklabels()[i].set_color('red')
        
        plt.tight_layout()
        plt.savefig(output_dir / f'dist_extremes_{metric}.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    # ä¿å­˜åˆ†å¸ƒç»Ÿè®¡ä¿¡æ¯åˆ°CSV
    dist_stats = data.groupby(['final_path', 'test_name'])[metric].describe()
    dist_stats.to_csv(output_dir / f'distribution_stats_{metric}.csv')

def compare_strategies(data, output_dir):
    """æ¯”è¾ƒlong-only, short-onlyå’Œcombinedç­–ç•¥è¡¨ç°"""
    # å®šä¹‰ç­–ç•¥ç±»å‹å’Œå¯¹åº”çš„æŒ‡æ ‡
    strategy_metrics = {
        'Combined': 'net_sharpe_ratio',
        'Long Only': 'net_sharpe_ratio_long_only',
        'Short Only': 'net_sharpe_ratio_short_only'
    }
    
    # å‡†å¤‡æ¯”è¾ƒæ•°æ®
    stats_data = []
    for strategy, metric in strategy_metrics.items():
        if metric in data.columns:
            # è®¡ç®—æ¯ä¸ªfinal_pathçš„å¹³å‡å€¼
            means_by_path = data.groupby(['final_path'])[metric].mean().reset_index()
            means_by_path['Strategy'] = strategy
            means_by_path['Metric'] = metric
            means_by_path = means_by_path.rename(columns={metric: 'Value'})
            stats_data.append(means_by_path)
            
            # è®¡ç®—æ¯ä¸ªtest_nameçš„å¹³å‡å€¼
            means_by_test = data.groupby(['test_name'])[metric].mean().reset_index()
            means_by_test['Strategy'] = strategy
            means_by_test['Metric'] = metric
            means_by_test = means_by_test.rename(columns={metric: 'Value'})
            stats_data.append(means_by_test)
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    if stats_data:
        all_stats = pd.concat(stats_data)
        
        # 1. æŒ‰final_pathç»˜åˆ¶ç­–ç•¥æ¯”è¾ƒ
        plt.figure(figsize=(14, 8))
        
        # æŒ‰final_pathç­›é€‰
        path_stats = all_stats[all_stats['final_path'].notna()]
        
        # ä½¿ç”¨seabornçš„barplotæ›´æ¸…æ™°åœ°å±•ç¤ºåˆ†ç»„æ•°æ®
        ax = sns.barplot(x='final_path', y='Value', hue='Strategy', data=path_stats,
                       palette=sns.color_palette(COLOR_SCHEME['line'], 3))
        
        ax.set_title('Strategy Comparison by Final Path')
        ax.set_xlabel('Final Path')
        ax.set_ylabel('Mean Sharpe Ratio')
        plt.xticks(rotation=45, ha='right')
        plt.legend(title='Strategy Type')
        
        plt.tight_layout()
        plt.savefig(output_dir / 'strategy_comparison_by_path.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. æŒ‰test_nameç»˜åˆ¶ç­–ç•¥æ¯”è¾ƒ
        plt.figure(figsize=(14, 8))
        
        # æŒ‰test_nameç­›é€‰
        test_stats = all_stats[all_stats['test_name'].notna()]
        
        ax = sns.barplot(x='test_name', y='Value', hue='Strategy', data=test_stats,
                       palette=sns.color_palette(COLOR_SCHEME['line'], 3))
        
        ax.set_title('Strategy Comparison by Test Name')
        ax.set_xlabel('Test Name')
        ax.set_ylabel('Mean Sharpe Ratio')
        plt.xticks(rotation=45, ha='right')
        plt.legend(title='Strategy Type')
        
        plt.tight_layout()
        plt.savefig(output_dir / 'strategy_comparison_by_test.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. ç­–ç•¥ä¹‹é—´çš„æ•´ä½“æ¯”è¾ƒï¼ˆä¸åŒºåˆ†è·¯å¾„å’Œæµ‹è¯•ï¼‰
        plt.figure(figsize=(10, 6))
        
        overall_stats = all_stats.groupby('Strategy')['Value'].mean().reset_index()
        overall_std = all_stats.groupby('Strategy')['Value'].std().reset_index()
        overall_stats['Std'] = overall_std['Value']
        
        ax = sns.barplot(x='Strategy', y='Value', data=overall_stats, 
                       palette=sns.color_palette(COLOR_SCHEME['line'], 3))
        
        # æ·»åŠ è¯¯å·®çº¿
        for i, row in overall_stats.iterrows():
            ax.errorbar(i, row['Value'], yerr=row['Std'], color='black', capsize=5)
        
        ax.set_title('Overall Strategy Comparison')
        ax.set_xlabel('Strategy Type')
        ax.set_ylabel('Mean Sharpe Ratio')
        
        plt.tight_layout()
        plt.savefig(output_dir / 'strategy_comparison_overall.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. ç­–ç•¥è¡¨ç°çš„åˆ†å¸ƒå›¾æ¯”è¾ƒ
        plt.figure(figsize=(12, 8))
        
        long_data = data['net_sharpe_ratio_long_only'].dropna()
        short_data = data['net_sharpe_ratio_short_only'].dropna()
        combined_data = data['net_sharpe_ratio'].dropna()
        
        all_values = pd.DataFrame({
            'Value': pd.concat([long_data, short_data, combined_data]),
            'Strategy': ['Long Only'] * len(long_data) + ['Short Only'] * len(short_data) + ['Combined'] * len(combined_data)
        })
        
        ax = sns.violinplot(x='Strategy', y='Value', data=all_values, 
                         palette=sns.color_palette(COLOR_SCHEME['line'], 3), inner='box')
        
        ax.set_title('Strategy Performance Distribution')
        ax.set_xlabel('Strategy Type')
        ax.set_ylabel('Sharpe Ratio')
        
        plt.tight_layout()
        plt.savefig(output_dir / 'strategy_comparison_violin.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # ä¿å­˜æ¯”è¾ƒæ•°æ®
        all_stats.to_csv(output_dir / 'strategy_comparison_stats.csv', index=False)
        overall_stats.to_csv(output_dir / 'strategy_comparison_overall.csv', index=False)

def generate_summary_table(data, metric, percentile, output_dir):
    """ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡è¡¨"""
    summary_stats = []
    
    # æŒ‰final_pathå’Œtest_nameåˆ†ç»„è®¡ç®—ç»Ÿè®¡é‡
    for (final_path, test_name), group in data.groupby(['final_path', 'test_name']):
        if not group[metric].empty:
            stats = {
                'final_path': final_path,
                'test_name': test_name,
                f'{metric}_mean': group[metric].mean(),
                f'{metric}_median': group[metric].median(),
                f'{metric}_std': group[metric].std(),
                f'{metric}_percentile_{percentile}': np.percentile(group[metric], percentile),
                f'{metric}_percentile_{100-percentile}': np.percentile(group[metric], 100-percentile),
                f'{metric}_max': group[metric].max(),
                f'{metric}_min': group[metric].min(),
                'count': len(group)
            }
            
            # æ·»åŠ ç­–ç•¥æ¯”è¾ƒæŒ‡æ ‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if 'net_sharpe_ratio_long_only' in group.columns:
                stats['sharpe_long_only_mean'] = group['net_sharpe_ratio_long_only'].mean()
            if 'net_sharpe_ratio_short_only' in group.columns:
                stats['sharpe_short_only_mean'] = group['net_sharpe_ratio_short_only'].mean()
                
            summary_stats.append(stats)
    
    if summary_stats:
        summary_df = pd.DataFrame(summary_stats)
        summary_df.to_csv(output_dir / f'summary_statistics_{metric}.csv', index=False)
        
        # æŒ‰å‡å€¼æ’åº
        sorted_df = summary_df.sort_values(by=f'{metric}_mean', ascending=False)
        
        # å–top 10å’Œbottom 10
        top_bottom = pd.concat([sorted_df.head(10), sorted_df.tail(10)])
        
        # åˆ›å»ºä¸€ä¸ªè§†è§‰æ‘˜è¦è¡¨æ ¼ï¼ˆä»…æ˜¾ç¤ºä¸»è¦åˆ—ï¼‰
        display_cols = ['final_path', 'test_name', f'{metric}_mean', f'{metric}_median', 
                         f'{metric}_percentile_{percentile}', f'{metric}_max', f'{metric}_min']
        
        fig, ax = plt.subplots(figsize=(12, max(8, len(top_bottom) * 0.4)))
        ax.axis('tight')
        ax.axis('off')
        
        # å°†æ•°æ®æ¡†è½¬æ¢ä¸ºè¡¨æ ¼æ•°æ®
        table_data = []
        headers = [col.replace(f'{metric}_', '') for col in display_cols]
        
        for _, row in top_bottom.reset_index(drop=True).iterrows():
            row_data = [row[col] for col in display_cols]
            formatted_row = []
            for v in row_data:
                if isinstance(v, float):
                    formatted_row.append(f'{v:.3f}')
                else:
                    formatted_row.append(str(v))
            table_data.append(formatted_row)
        
        table = ax.table(cellText=table_data, colLabels=headers, cellLoc='center', loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1.2, 1.5)
        
        # ä¸ºtop 10å’Œbottom 10è®¾ç½®ä¸åŒçš„é¢œè‰²
        for i in range(1, 11):
            for j in range(len(display_cols)):
                cell = table[(i, j)]
                cell.set_facecolor('#d8f3dc')  # æµ…ç»¿è‰²
        
        for i in range(11, len(top_bottom) + 1):
            for j in range(len(display_cols)):
                cell = table[(i, j)]
                cell.set_facecolor('#ffdde1')  # æµ…çº¢è‰²
        
        plt.title(f'Top 10 and Bottom 10 Combinations by {METRICS_DICT.get(metric, metric)}', pad=20)
        plt.tight_layout()
        plt.savefig(output_dir / f'summary_top_bottom_{metric}.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # æ±‡æ€»ç»Ÿè®¡è¡¨ - æŒ‰final_path
        path_summary = data.groupby('final_path')[metric].agg(['mean', 'std', 'median', 'min', 'max']).reset_index()
        path_summary.to_csv(output_dir / f'summary_by_path_{metric}.csv', index=False)
        
        # æ±‡æ€»ç»Ÿè®¡è¡¨ - æŒ‰test_name
        test_summary = data.groupby('test_name')[metric].agg(['mean', 'std', 'median', 'min', 'max']).reset_index()
        test_summary.to_csv(output_dir / f'summary_by_test_{metric}.csv', index=False)

# ç¤ºä¾‹ç”¨æ³•:
run_analysis(
    df=eval_res,
    summary_dir=summary_dir,
    metrics=['net_sharpe_ratio', 'net_calmar_ratio', 'net_sharpe_ratio_long_only'],
    percentiles=[90, 75]
)